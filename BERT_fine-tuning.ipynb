{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim import optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss,BCEWithLogitsLoss\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "#from transformers.optimization import BertAdam, WarmupLinearSchedule\n",
    "from sklearn.metrics import precision_recall_curve,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/yhchou/Desktop/csv_file/nownews/news_content_0514.csv')\n",
    "a= []\n",
    "for title in df['title']:\n",
    "    title = title.replace('| 政治 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 影音 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 節目 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 娛樂 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 焦點 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 觀點 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 國際 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 運動 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 房產 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 財經 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 兩岸 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 新奇 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 生活 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 地方 | NOWnews 今日新聞','')\n",
    "    a.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['Unnamed: 0.1','content'], axis=1)\n",
    "data['title'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>李來希扯「小燈泡」堅持不道歉！郭昱晴氣炸：你就是無恥</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>恐遭國民黨開除黨籍！李來希搬「46年經歷」狠嗆：我好怕</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>因選舉欠下2000萬全數還清　柯文哲：陳佩琪不會怪我了！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>李來希挺韓失態扯小燈泡！她曝「最大受害者」：對立提升</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>白宮官員戴MIT口罩　外交部欣慰：抗疫期間發揮效益</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>233</td>\n",
       "      <td>盧秀燕市場當助手、致贈康乃馨慶祝母親節</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>234</td>\n",
       "      <td>新冠肺炎疫情趨緩　中市校園16日逐步開放</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>235</td>\n",
       "      <td>美食巷仔內／當季「馬頭魚」肥嫩鮮甜　新北網購買得到</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>236</td>\n",
       "      <td>避免棉絮飛舞　清總兵署進行木棉樹果摘除作業</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>237</td>\n",
       "      <td>榮服處致贈康乃馨及蛋糕　祝福辛苦的媽媽們母親節快樂</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                          title  news_label\n",
       "0             0    李來希扯「小燈泡」堅持不道歉！郭昱晴氣炸：你就是無恥            0\n",
       "1             1   恐遭國民黨開除黨籍！李來希搬「46年經歷」狠嗆：我好怕            0\n",
       "2             2  因選舉欠下2000萬全數還清　柯文哲：陳佩琪不會怪我了！            0\n",
       "3             3    李來希挺韓失態扯小燈泡！她曝「最大受害者」：對立提升            0\n",
       "4             4     白宮官員戴MIT口罩　外交部欣慰：抗疫期間發揮效益            0\n",
       "..          ...                            ...         ...\n",
       "471         233           盧秀燕市場當助手、致贈康乃馨慶祝母親節           13\n",
       "472         234          新冠肺炎疫情趨緩　中市校園16日逐步開放           13\n",
       "473         235    美食巷仔內／當季「馬頭魚」肥嫩鮮甜　新北網購買得到            13\n",
       "474         236         避免棉絮飛舞　清總兵署進行木棉樹果摘除作業           13\n",
       "475         237     榮服處致贈康乃馨及蛋糕　祝福辛苦的媽媽們母親節快樂           13\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['news_label'].isin([1])]\n",
    "data = data[~data['news_label'].isin([2])]\n",
    "data = data[~data['news_label'].isin([4])]\n",
    "data = data[~data['news_label'].isin([5])]\n",
    "data = data[~data['news_label'].isin([8])]\n",
    "\n",
    "\n",
    "data['news_label'].replace(3,1,inplace=True)\n",
    "data['news_label'].replace(6,2,inplace=True)\n",
    "data['news_label'].replace(7,3,inplace=True)\n",
    "data['news_label'].replace(9,4,inplace=True)\n",
    "data['news_label'].replace(10,5,inplace=True)\n",
    "data['news_label'].replace(11,6,inplace=True)\n",
    "data['news_label'].replace(12,7,inplace=True)\n",
    "data['news_label'].replace(13,8,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data= shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 250\n",
    "data =data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.iloc[0:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.iloc[cut:306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>NBA／字母哥四兄弟合體再等等　最小胞弟決定留在歐洲</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>中職／還我完全比賽！前兄弟洋投賈羅拉加向大聯盟討公道</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>奧運／郭泰源對日本先發球威盡失　原來是這原因</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>中職／林安可砲火延燒國外　招牌辮子成外媒關注焦點</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>NBA／球隊黑幕是誰爆料的？喬丹在紀錄片指明是他</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NBA／喬丹對待隊友近乎苛求　巴克利：他也是會挑人的</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>避免棉絮飛舞　清總兵署進行木棉樹果摘除作業</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>韓國文化底蘊大輸日本？台灣人抖出「4關鍵原因」：難怪</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>中國「兩會」前夕加強維穩　維權人士曝：疫情激起民怨</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>疫情對YouTuber沒影響？蔡阿嘎曝「內幕」：收入慘降8成</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>影／外送平台大比拼！實測接一單就可賺一百？</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>白宮官員戴MIT口罩　外交部欣慰：抗疫期間發揮效益</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>影／24小時美味不打烊　彰化焢肉飯地圖讓你吃飽飽</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>前年舉債2000萬拚市長連任　柯文哲用選舉補助款還清貸款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>疫情惡化！吉林「封城」　客運火車停止出入</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>台灣專家登英國《每日電訊報》  首赴武漢揭病毒人傳人</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>紐約新冠確診兒童臟器發炎似「川崎症」　至少73例、3死</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>6月6日罷韓是否投票？陳其邁回應了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>穆熙妍專欄／灰色的眼淚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NBA／雖與前隊友不歡而散　KD合夥人：他未曾後悔去勇士</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>滴妹飲料店被看衰？行家分析「3關鍵問題」被大推專業</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>開罰水神金額高過罰練台生！柯文哲：罰則太輕消防法要改</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>稻江科技暨管理學院今宣布退場　不再招收新生</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>為何紓困案會被罵爆？台人曝「真實心聲」：這挺不下去啦</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>外送員包上貼送餐原則！「4要3不」曝　網見1亮點全笑歪</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>台灣人親美還是親中？民調出爐「驚人對比」　全場看傻</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>中市東大溪魚群暴斃　居民自嘲：母親節禮物？</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>江啟臣澎湖「接地氣」之旅　致贈康乃馨展現高人氣</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>高傳染性「甲殼類」病毒沒在怕！中國饕客暴吃80萬小龍蝦</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>超市有啥好吃的甜點？老饕狂推「這2樣」：CP值高又美味</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>彰化警分局警員疑酒駕拒測　被自己人攔查</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>安親班停課沒處去！兩臘腸犬陪把拔上班　擔任最萌小快遞</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>中職／生涯首度先發守中外野　陳傑憲：對生涯有益不排斥</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>韓國暖心弟跑步進警局！「1舉動」3.1萬人讚爆：太可愛</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>民間企業真比不上公務員？眾狂喊「2關鍵優勢」：想清楚</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>影／8校晉級搶全國決賽門票　邱建富鼓勵選手創造好成績</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>韓國瑜撥5千萬紓困　龔明鑫：歡迎</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>女星穿情趣衣勾引　大戰柯叔元 「男上女下」：他比較累</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>視導潛艦防疫　海軍副司令唐華要求官兵勤洗手、戴口罩</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>NBA／復賽日程不斷推遲　湖人前鋒：我聽說要十月</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>紐約100名兒童「川崎症」發病　州長：疑與新冠病毒相關</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>為何紓困案會被罵爆？台人曝「真實心聲」：這挺不下去啦</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>中職／施子謙封鎖悍將打線　統一客場終止6連敗</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NBA／阿泰初到湖人就找Kobe麻煩　禪師看不下去親自調停</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>39歲張娜拉不結婚　跟3男「借精生子」圓當媽夢</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>影／員林火車站大廳花卉促銷　民眾：好像佈置靈堂</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>日職／來自大王的祝福！火腿慶祝母親節　王柏融感謝媽媽</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>平民巨星／因選秀出道！李佳薇搖身變評審　傳授星路秘訣</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>中國吉林、武漢爆跨省感染增17例　日NHK警告：疫情回溫</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>男星捐贈骨髓給少女　守14年約定超暖心</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>多國挺台進WHO！為何敵不過中國反對？　眾人曝致命敗筆</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>民進黨黨職改選　相互攻訐砲火猛　卓榮泰點名台北市黨部</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>遭民眾惡意「吐口水」！英鐵路員工不幸染疫　2周內過世</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>生技產業沉浮10年走出新格局　全面普篩最強防疫股</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  news_label\n",
       "369      NBA／字母哥四兄弟合體再等等　最小胞弟決定留在歐洲            3\n",
       "125      中職／還我完全比賽！前兄弟洋投賈羅拉加向大聯盟討公道            3\n",
       "435      房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼            6\n",
       "120          奧運／郭泰源對日本先發球威盡失　原來是這原因            3\n",
       "126        中職／林安可砲火延燒國外　招牌辮子成外媒關注焦點            3\n",
       "373        NBA／球隊黑幕是誰爆料的？喬丹在紀錄片指明是他            3\n",
       "124      NBA／喬丹對待隊友近乎苛求　巴克利：他也是會挑人的            3\n",
       "455      房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼            7\n",
       "474           避免棉絮飛舞　清總兵署進行木棉樹果摘除作業            8\n",
       "441      韓國文化底蘊大輸日本？台灣人抖出「4關鍵原因」：難怪            6\n",
       "183       中國「兩會」前夕加強維穩　維權人士曝：疫情激起民怨            5\n",
       "53   疫情對YouTuber沒影響？蔡阿嘎曝「內幕」：收入慘降8成            1\n",
       "300           影／外送平台大比拼！實測接一單就可賺一百？            1\n",
       "4         白宮官員戴MIT口罩　外交部欣慰：抗疫期間發揮效益            0\n",
       "454        影／24小時美味不打烊　彰化焢肉飯地圖讓你吃飽飽            7\n",
       "6      前年舉債2000萬拚市長連任　柯文哲用選舉補助款還清貸款            0\n",
       "170            疫情惡化！吉林「封城」　客運火車停止出入            5\n",
       "417      台灣專家登英國《每日電訊報》  首赴武漢揭病毒人傳人            5\n",
       "348     紐約新冠確診兒童臟器發炎似「川崎症」　至少73例、3死            2\n",
       "244               6月6日罷韓是否投票？陳其邁回應了            0\n",
       "58                      穆熙妍專欄／灰色的眼淚            1\n",
       "127    NBA／雖與前隊友不歡而散　KD合夥人：他未曾後悔去勇士            3\n",
       "167       滴妹飲料店被看衰？行家分析「3關鍵問題」被大推專業            4\n",
       "246      開罰水神金額高過罰練台生！柯文哲：罰則太輕消防法要改            0\n",
       "234           稻江科技暨管理學院今宣布退場　不再招收新生            8\n",
       "194      為何紓困案會被罵爆？台人曝「真實心聲」：這挺不下去啦            6\n",
       "190     外送員包上貼送餐原則！「4要3不」曝　網見1亮點全笑歪            6\n",
       "115       台灣人親美還是親中？民調出爐「驚人對比」　全場看傻            2\n",
       "467           中市東大溪魚群暴斃　居民自嘲：母親節禮物？            8\n",
       "469         江啟臣澎湖「接地氣」之旅　致贈康乃馨展現高人氣            8\n",
       "341     高傳染性「甲殼類」病毒沒在怕！中國饕客暴吃80萬小龍蝦            2\n",
       "209     超市有啥好吃的甜點？老饕狂推「這2樣」：CP值高又美味            7\n",
       "226             彰化警分局警員疑酒駕拒測　被自己人攔查            8\n",
       "198      安親班停課沒處去！兩臘腸犬陪把拔上班　擔任最萌小快遞            6\n",
       "360      中職／生涯首度先發守中外野　陳傑憲：對生涯有益不排斥            3\n",
       "347     韓國暖心弟跑步進警局！「1舉動」3.1萬人讚爆：太可愛            2\n",
       "188      民間企業真比不上公務員？眾狂喊「2關鍵優勢」：想清楚            6\n",
       "225      影／8校晉級搶全國決賽門票　邱建富鼓勵選手創造好成績            8\n",
       "9                  韓國瑜撥5千萬紓困　龔明鑫：歡迎            0\n",
       "60       女星穿情趣衣勾引　大戰柯叔元 「男上女下」：他比較累            1\n",
       "239       視導潛艦防疫　海軍副司令唐華要求官兵勤洗手、戴口罩            0\n",
       "367        NBA／復賽日程不斷推遲　湖人前鋒：我聽說要十月            3\n",
       "110     紐約100名兒童「川崎症」發病　州長：疑與新冠病毒相關            2\n",
       "216      為何紓困案會被罵爆？台人曝「真實心聲」：這挺不下去啦            7\n",
       "363          中職／施子謙封鎖悍將打線　統一客場終止6連敗            3\n",
       "131   NBA／阿泰初到湖人就找Kobe麻煩　禪師看不下去親自調停            3\n",
       "66          39歲張娜拉不結婚　跟3男「借精生子」圓當媽夢            1\n",
       "230         影／員林火車站大廳花卉促銷　民眾：好像佈置靈堂            8\n",
       "371      日職／來自大王的祝福！火腿慶祝母親節　王柏融感謝媽媽            3\n",
       "55       平民巨星／因選秀出道！李佳薇搖身變評審　傳授星路秘訣            1\n",
       "181    中國吉林、武漢爆跨省感染增17例　日NHK警告：疫情回溫            5\n",
       "61              男星捐贈骨髓給少女　守14年約定超暖心            1\n",
       "195     多國挺台進WHO！為何敵不過中國反對？　眾人曝致命敗筆            6\n",
       "254      民進黨黨職改選　相互攻訐砲火猛　卓榮泰點名台北市黨部            0\n",
       "116      遭民眾惡意「吐口水」！英鐵路員工不幸染疫　2周內過世            2\n",
       "400        生技產業沉浮10年走出新格局　全面普篩最強防疫股            4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=False)\n",
    "# 封装类\n",
    "class DataPrecessForSingleSentence(object):\n",
    "    def __init__(self, bert_tokenizer, max_workers=10):\n",
    "        \"\"\"\n",
    "        bert_tokenizer :分词器\n",
    "        dataset        :包含列名为'text'与'label'的pandas dataframe\n",
    "        \"\"\"\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        # 创建多线程池\n",
    "        self.pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        # 获取文本与标签\n",
    "    def get_input(self, dataset, max_seq_len=30):\n",
    "        \"\"\"\n",
    "        通过多线程（因为notebook中多进程使用存在一些问题）的方式对输入文本进行分词、ID化、截断、填充等流程得到最终的可用于模型输入的序列。\n",
    "        \n",
    "        入参:\n",
    "            dataset     : pandas的dataframe格式，包含两列，第一列为文本，第二列为标签。标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "            max_seq_len : 目标序列长度，该值需要预先对文本长度进行分别得到，可以设置为小于等于512（BERT的最长文本序列长度为512）的整数。\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "            labels      : 标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "        \n",
    "            \n",
    "        \"\"\"\n",
    "        sentences = dataset.iloc[:, 0].tolist()\n",
    "        labels = dataset.iloc[:, 1].tolist()\n",
    "        # 切词\n",
    "        tokens_seq = list(\n",
    "            self.pool.map(self.bert_tokenizer.tokenize, sentences))\n",
    "        # 获取定长序列及其mask\n",
    "        result = list(\n",
    "            self.pool.map(self.trunate_and_pad, tokens_seq,\n",
    "                          [max_seq_len] * len(tokens_seq)))\n",
    "        seqs = [i[0] for i in result]\n",
    "        seq_masks = [i[1] for i in result]\n",
    "        seq_segments = [i[2] for i in result]\n",
    "        return seqs, seq_masks, seq_segments, labels\n",
    "    def trunate_and_pad(self, seq, max_seq_len):\n",
    "        \"\"\"\n",
    "        1. 因为本类处理的是单句序列，按照BERT中的序列处理方式，需要在输入序列头尾分别拼接特殊字符'CLS'与'SEP'，\n",
    "           因此不包含两个特殊字符的序列长度应该小于等于max_seq_len-2，如果序列长度大于该值需要那么进行截断。\n",
    "        2. 对输入的序列 最终形成['CLS',seq,'SEP']的序列，该序列的长度如果小于max_seq_len，那么使用0进行填充。\n",
    "        \n",
    "        入参: \n",
    "            seq         : 输入序列，在本处其为单个句子。\n",
    "            max_seq_len : 拼接'CLS'与'SEP'这两个特殊字符后的序列长度\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "        \"\"\"\n",
    "        # 对超长序列进行截断\n",
    "        if len(seq) > (max_seq_len - 2):\n",
    "            seq = seq[0:(max_seq_len - 2)]\n",
    "        # 分别在首尾拼接特殊符号\n",
    "        seq = ['[CLS]'] + seq + ['[SEP]']\n",
    "        # ID化\n",
    "        seq = self.bert_tokenizer.convert_tokens_to_ids(seq)\n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (max_seq_len - len(seq))\n",
    "        # 创建seq_mask\n",
    "        seq_mask = [1] * len(seq) + padding\n",
    "        # 创建seq_segment\n",
    "        seq_segment = [0] * len(seq) + padding\n",
    "        # 对seq拼接填充序列\n",
    "        seq += padding\n",
    "        assert len(seq) == max_seq_len\n",
    "        assert len(seq_mask) == max_seq_len\n",
    "        assert len(seq_segment) == max_seq_len\n",
    "        return seq, seq_mask, seq_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)\n",
    "# 产生输入ju 数据\n",
    "seqs, seq_masks, seq_segments, labels = processor.get_input(dataset=data_train, max_seq_len=30)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=9)\n",
    "t_seqs = torch.tensor(seqs, dtype=torch.long)\n",
    "t_seq_masks = torch.tensor(seq_masks, dtype = torch.long)\n",
    "t_seq_segments = torch.tensor(seq_segments, dtype = torch.long)\n",
    "t_labels = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "train_data = TensorDataset(t_seqs, t_seq_masks, t_seq_segments, t_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloder = DataLoader(dataset= train_data, sampler= train_sampler,batch_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)\n",
    "# 产生输入ju 数据\n",
    "te_seqs, te_seq_masks, te_seq_segments, te_labels = processor.get_input(dataset=data_test, max_seq_len=30)\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=14)\n",
    "te_seqs = torch.tensor(te_seqs, dtype=torch.long)\n",
    "te_seq_masks = torch.tensor(te_seq_masks, dtype = torch.long)\n",
    "te_seq_segments = torch.tensor(te_seq_segments, dtype = torch.long)\n",
    "te_labels = torch.tensor(te_labels, dtype = torch.long)\n",
    "\n",
    "test_data = TensorDataset(te_seqs, te_seq_masks, te_seq_segments, te_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloder = DataLoader(dataset= test_data, sampler= test_sampler,batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "classification acc: 0.108\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, train_dataloder, compute_acc=True)\n",
    "print(\"classification acc:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 10.186, acc: 0.625\n",
      "[epoch 1] loss: 10.186, acc: 0.872\n",
      "[epoch 2] loss: 10.076, acc: 0.625\n",
      "[epoch 2] loss: 10.076, acc: 0.896\n",
      "[epoch 3] loss: 10.162, acc: 0.625\n",
      "[epoch 3] loss: 10.162, acc: 0.872\n",
      "[epoch 4] loss: 10.198, acc: 0.643\n",
      "[epoch 4] loss: 10.198, acc: 0.888\n",
      "[epoch 5] loss: 10.050, acc: 0.661\n",
      "[epoch 5] loss: 10.050, acc: 0.852\n",
      "[epoch 6] loss: 10.046, acc: 0.643\n",
      "[epoch 6] loss: 10.046, acc: 0.860\n",
      "[epoch 7] loss: 10.532, acc: 0.643\n",
      "[epoch 7] loss: 10.532, acc: 0.868\n",
      "[epoch 8] loss: 10.027, acc: 0.643\n",
      "[epoch 8] loss: 10.027, acc: 0.848\n",
      "[epoch 9] loss: 10.277, acc: 0.625\n",
      "[epoch 9] loss: 10.277, acc: 0.880\n",
      "[epoch 10] loss: 10.500, acc: 0.607\n",
      "[epoch 10] loss: 10.500, acc: 0.872\n",
      "[epoch 11] loss: 10.292, acc: 0.643\n",
      "[epoch 11] loss: 10.292, acc: 0.848\n",
      "[epoch 12] loss: 10.289, acc: 0.625\n",
      "[epoch 12] loss: 10.289, acc: 0.872\n",
      "[epoch 13] loss: 10.053, acc: 0.607\n",
      "[epoch 13] loss: 10.053, acc: 0.852\n",
      "[epoch 14] loss: 10.107, acc: 0.661\n",
      "[epoch 14] loss: 10.107, acc: 0.848\n",
      "[epoch 15] loss: 10.157, acc: 0.625\n",
      "[epoch 15] loss: 10.157, acc: 0.860\n",
      "[epoch 16] loss: 10.439, acc: 0.625\n",
      "[epoch 16] loss: 10.439, acc: 0.868\n",
      "[epoch 17] loss: 10.297, acc: 0.625\n",
      "[epoch 17] loss: 10.297, acc: 0.888\n",
      "[epoch 18] loss: 9.761, acc: 0.625\n",
      "[epoch 18] loss: 9.761, acc: 0.860\n",
      "[epoch 19] loss: 10.626, acc: 0.625\n",
      "[epoch 19] loss: 10.626, acc: 0.868\n",
      "[epoch 20] loss: 10.207, acc: 0.625\n",
      "[epoch 20] loss: 10.207, acc: 0.880\n",
      "[epoch 21] loss: 10.489, acc: 0.589\n",
      "[epoch 21] loss: 10.489, acc: 0.848\n",
      "[epoch 22] loss: 10.167, acc: 0.625\n",
      "[epoch 22] loss: 10.167, acc: 0.876\n",
      "[epoch 23] loss: 10.239, acc: 0.643\n",
      "[epoch 23] loss: 10.239, acc: 0.856\n",
      "[epoch 24] loss: 10.109, acc: 0.571\n",
      "[epoch 24] loss: 10.109, acc: 0.868\n",
      "[epoch 25] loss: 10.503, acc: 0.625\n",
      "[epoch 25] loss: 10.503, acc: 0.852\n",
      "[epoch 26] loss: 10.230, acc: 0.625\n",
      "[epoch 26] loss: 10.230, acc: 0.880\n",
      "[epoch 27] loss: 9.994, acc: 0.625\n",
      "[epoch 27] loss: 9.994, acc: 0.876\n",
      "[epoch 28] loss: 9.753, acc: 0.643\n",
      "[epoch 28] loss: 9.753, acc: 0.876\n",
      "[epoch 29] loss: 10.233, acc: 0.625\n",
      "[epoch 29] loss: 10.233, acc: 0.860\n",
      "[epoch 30] loss: 10.248, acc: 0.661\n",
      "[epoch 30] loss: 10.248, acc: 0.892\n",
      "[epoch 31] loss: 10.011, acc: 0.625\n",
      "[epoch 31] loss: 10.011, acc: 0.864\n",
      "[epoch 32] loss: 10.034, acc: 0.625\n",
      "[epoch 32] loss: 10.034, acc: 0.888\n",
      "[epoch 33] loss: 10.171, acc: 0.607\n",
      "[epoch 33] loss: 10.171, acc: 0.880\n",
      "[epoch 34] loss: 10.487, acc: 0.679\n",
      "[epoch 34] loss: 10.487, acc: 0.868\n",
      "[epoch 35] loss: 10.609, acc: 0.643\n",
      "[epoch 35] loss: 10.609, acc: 0.856\n",
      "[epoch 36] loss: 9.756, acc: 0.643\n",
      "[epoch 36] loss: 9.756, acc: 0.832\n",
      "[epoch 37] loss: 10.618, acc: 0.571\n",
      "[epoch 37] loss: 10.618, acc: 0.880\n",
      "[epoch 38] loss: 9.811, acc: 0.625\n",
      "[epoch 38] loss: 9.811, acc: 0.900\n",
      "[epoch 39] loss: 10.540, acc: 0.643\n",
      "[epoch 39] loss: 10.540, acc: 0.880\n",
      "[epoch 40] loss: 10.492, acc: 0.643\n",
      "[epoch 40] loss: 10.492, acc: 0.868\n",
      "[epoch 41] loss: 10.647, acc: 0.643\n",
      "[epoch 41] loss: 10.647, acc: 0.856\n",
      "[epoch 42] loss: 9.828, acc: 0.661\n",
      "[epoch 42] loss: 9.828, acc: 0.880\n",
      "[epoch 43] loss: 9.897, acc: 0.625\n",
      "[epoch 43] loss: 9.897, acc: 0.840\n",
      "[epoch 44] loss: 9.801, acc: 0.607\n",
      "[epoch 44] loss: 9.801, acc: 0.884\n",
      "[epoch 45] loss: 10.331, acc: 0.607\n",
      "[epoch 45] loss: 10.331, acc: 0.836\n",
      "[epoch 46] loss: 10.318, acc: 0.607\n",
      "[epoch 46] loss: 10.318, acc: 0.904\n",
      "[epoch 47] loss: 10.088, acc: 0.643\n",
      "[epoch 47] loss: 10.088, acc: 0.844\n",
      "[epoch 48] loss: 10.344, acc: 0.661\n",
      "[epoch 48] loss: 10.344, acc: 0.852\n",
      "[epoch 49] loss: 10.107, acc: 0.661\n",
      "[epoch 49] loss: 10.107, acc: 0.884\n",
      "[epoch 50] loss: 10.070, acc: 0.679\n",
      "[epoch 50] loss: 10.070, acc: 0.852\n",
      "[epoch 51] loss: 9.995, acc: 0.661\n",
      "[epoch 51] loss: 9.995, acc: 0.900\n",
      "[epoch 52] loss: 10.357, acc: 0.643\n",
      "[epoch 52] loss: 10.357, acc: 0.892\n",
      "[epoch 53] loss: 10.252, acc: 0.661\n",
      "[epoch 53] loss: 10.252, acc: 0.872\n",
      "[epoch 54] loss: 10.371, acc: 0.625\n",
      "[epoch 54] loss: 10.371, acc: 0.872\n",
      "[epoch 55] loss: 10.266, acc: 0.607\n",
      "[epoch 55] loss: 10.266, acc: 0.888\n",
      "[epoch 56] loss: 10.273, acc: 0.589\n",
      "[epoch 56] loss: 10.273, acc: 0.868\n",
      "[epoch 57] loss: 10.225, acc: 0.643\n",
      "[epoch 57] loss: 10.225, acc: 0.876\n",
      "[epoch 58] loss: 10.064, acc: 0.643\n",
      "[epoch 58] loss: 10.064, acc: 0.864\n",
      "[epoch 59] loss: 10.336, acc: 0.625\n",
      "[epoch 59] loss: 10.336, acc: 0.856\n",
      "[epoch 60] loss: 10.161, acc: 0.661\n",
      "[epoch 60] loss: 10.161, acc: 0.896\n",
      "[epoch 61] loss: 10.362, acc: 0.643\n",
      "[epoch 61] loss: 10.362, acc: 0.860\n",
      "[epoch 62] loss: 10.156, acc: 0.661\n",
      "[epoch 62] loss: 10.156, acc: 0.896\n",
      "[epoch 63] loss: 10.353, acc: 0.625\n",
      "[epoch 63] loss: 10.353, acc: 0.884\n",
      "[epoch 64] loss: 10.257, acc: 0.661\n",
      "[epoch 64] loss: 10.257, acc: 0.884\n",
      "[epoch 65] loss: 10.222, acc: 0.661\n",
      "[epoch 65] loss: 10.222, acc: 0.888\n",
      "[epoch 66] loss: 10.068, acc: 0.589\n",
      "[epoch 66] loss: 10.068, acc: 0.868\n",
      "[epoch 67] loss: 10.158, acc: 0.679\n",
      "[epoch 67] loss: 10.158, acc: 0.868\n",
      "[epoch 68] loss: 9.967, acc: 0.679\n",
      "[epoch 68] loss: 9.967, acc: 0.888\n",
      "[epoch 69] loss: 10.411, acc: 0.643\n",
      "[epoch 69] loss: 10.411, acc: 0.888\n",
      "[epoch 70] loss: 10.249, acc: 0.643\n",
      "[epoch 70] loss: 10.249, acc: 0.876\n",
      "[epoch 71] loss: 10.025, acc: 0.661\n",
      "[epoch 71] loss: 10.025, acc: 0.864\n",
      "[epoch 72] loss: 10.229, acc: 0.661\n",
      "[epoch 72] loss: 10.229, acc: 0.868\n",
      "[epoch 73] loss: 10.064, acc: 0.679\n",
      "[epoch 73] loss: 10.064, acc: 0.888\n",
      "[epoch 74] loss: 10.195, acc: 0.625\n",
      "[epoch 74] loss: 10.195, acc: 0.884\n",
      "[epoch 75] loss: 10.159, acc: 0.625\n",
      "[epoch 75] loss: 10.159, acc: 0.848\n",
      "[epoch 76] loss: 10.450, acc: 0.643\n",
      "[epoch 76] loss: 10.450, acc: 0.904\n",
      "[epoch 77] loss: 10.180, acc: 0.643\n",
      "[epoch 77] loss: 10.180, acc: 0.872\n",
      "[epoch 78] loss: 10.143, acc: 0.661\n",
      "[epoch 78] loss: 10.143, acc: 0.888\n",
      "[epoch 79] loss: 10.530, acc: 0.625\n",
      "[epoch 79] loss: 10.530, acc: 0.868\n",
      "[epoch 80] loss: 9.959, acc: 0.643\n",
      "[epoch 80] loss: 9.959, acc: 0.872\n",
      "[epoch 81] loss: 9.995, acc: 0.679\n",
      "[epoch 81] loss: 9.995, acc: 0.900\n",
      "[epoch 82] loss: 9.870, acc: 0.643\n",
      "[epoch 82] loss: 9.870, acc: 0.868\n",
      "[epoch 83] loss: 10.241, acc: 0.607\n",
      "[epoch 83] loss: 10.241, acc: 0.892\n",
      "[epoch 84] loss: 10.186, acc: 0.643\n",
      "[epoch 84] loss: 10.186, acc: 0.840\n",
      "[epoch 85] loss: 9.987, acc: 0.625\n",
      "[epoch 85] loss: 9.987, acc: 0.876\n",
      "[epoch 86] loss: 10.552, acc: 0.625\n",
      "[epoch 86] loss: 10.552, acc: 0.872\n",
      "[epoch 87] loss: 10.084, acc: 0.643\n",
      "[epoch 87] loss: 10.084, acc: 0.860\n",
      "[epoch 88] loss: 10.464, acc: 0.643\n",
      "[epoch 88] loss: 10.464, acc: 0.876\n",
      "[epoch 89] loss: 10.004, acc: 0.661\n",
      "[epoch 89] loss: 10.004, acc: 0.872\n",
      "[epoch 90] loss: 10.021, acc: 0.589\n",
      "[epoch 90] loss: 10.021, acc: 0.864\n",
      "[epoch 91] loss: 10.228, acc: 0.589\n",
      "[epoch 91] loss: 10.228, acc: 0.848\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-9)\n",
    "\n",
    "\n",
    "EPOCHS = 150  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in train_dataloder:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "        #print(labels)\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    _, acc_test = get_predictions(model, test_dataloder, compute_acc=True)\n",
    "    _, acc_train = get_predictions(model, train_dataloder, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc_test))\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers.optimization import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataloder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.01\n",
    "    },\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-05)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存储每一个batch的loss\n",
    "loss_collect = []\n",
    "for i in trange(10, desc='Epoch'):\n",
    "    for step, batch_data in enumerate(tqdm.notebook.tqdm_notebook(train_dataloder, desc='Iteration')):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data\n",
    "        \n",
    "        print(batch_seq_segments)\n",
    "        # 对标签进行onehot编码\n",
    "        one_hot = torch.zeros(batch_labels.size(0), 28).long()\n",
    "        one_hot_batch_labels = one_hot.scatter_(\n",
    "            dim=1,\n",
    "            index=torch.unsqueeze(batch_labels, dim=1),\n",
    "            src=torch.ones(batch_labels.size(0), 28).long())\n",
    "\n",
    "        logits = model(batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = logits.softmax(dim=1)\n",
    "        loss_function = CrossEntropyLoss()\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        loss_collect.append(loss.item())\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37new",
   "language": "python",
   "name": "py37_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
