{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nownews 爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title = []\n",
    "news_id = []\n",
    "news_dict = {}\n",
    "news_label = []\n",
    "dic = ['politics','clips','show','entertainment','column','forum-2','global','sport','house2','finance','chinaindex',\n",
    "           'novelty','life','local']\n",
    "\n",
    "\n",
    "'''\n",
    "politics : 政治\n",
    "clips : 影音\n",
    "show : 節目\n",
    "entertainment : 娛樂\n",
    "column : 焦點\n",
    "forum-2 : 觀點\n",
    "global : 國際\n",
    "sport : 運動\n",
    "house2 : 房產\n",
    "finance : 財經\n",
    "chinaindex : 兩岸\n",
    "novelty : 新奇\n",
    "life : 生活\n",
    "local : 地方\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(dic)):\n",
    "    url ='https://gcs-static-json-lb.nownews.com/api/v1/cat/'+ dic[i] +'.json'\n",
    "    ua = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\"\n",
    "\n",
    "    with requests.request('GET', url, headers={'User-agent': ua}) as res:\n",
    "        content = res.text  # 获取HTML的内容\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    newDictionary = json.loads(str(soup))\n",
    "\n",
    "    for j in range(len(newDictionary['data']['newsList'])):\n",
    "        #news_title.append(newDictionary['data']['newsList'][i]['postTitle'])\n",
    "        news_id.append(newDictionary['data']['newsList'][j]['id'])\n",
    "        news_label.append(i)\n",
    "    \n",
    "    \n",
    "    #print('news_id : ',news_id)\n",
    "    #print('news_label : ',news_label)\n",
    "        #news_label.append(i)\n",
    "    #l2 = list(set(news_id))\n",
    "    #new ={'politics':l2}\n",
    "    #news_dict.update({'politics_id':l2})\n",
    "    #print(dic[i],len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_article = []\n",
    "news_title =[]\n",
    "for categroy in range(len(dic)):\n",
    "    \n",
    "    for i in range(17):\n",
    "        url = \"https://www.nownews.com/news/\"+dic[categroy]+\"/\"+news_id[categroy*17 + i]\n",
    "        ua = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\"\n",
    "        news_content = []\n",
    "        #print('url : ',url)\n",
    "        with requests.request('GET',url,headers = {'User-agent':ua}) as res_new:\n",
    "            content = res_new.text          #获取HTML的内容\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        content_tags = soup.find_all(\"div\",class_=\"newsMsg\")\n",
    "        title_tags = soup.find_all(\"title\")\n",
    "        for index,tag in enumerate(content_tags):\n",
    "            \n",
    "            \n",
    "            #sentence = re.sub(r\"^\\s+|\\s+$\", \"\", content_tags[index].text)\n",
    "            #sentence = content_tags[index].text\n",
    "            #words = list(jieba.cut(\" \".join(jieba.cut(sentence.split(',')[0]))))\n",
    "            #jieba.cut(line.split(',')\n",
    "            \n",
    "            news_article.append(content_tags[index].text)\n",
    "            news_title.append(title_tags[index].text)\n",
    "    for i in range(len(news_article)):\n",
    "        news_article[i] = re.sub(r\"^\\s+|\\s+$\", \"\", news_article[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list(zip(news_title,news_article,news_label)),columns =['title', 'content','news_label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('news_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = np.random.permutation(230)\n",
    "#df = df.take(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r'C:\\Users\\yhchou\\Desktop\\csv_file\\nownews\\news_content_0514.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "result = pd.concat(frames)#keys=['2020-05-11', '2020-05-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(r'C:\\Users\\yhchou\\Desktop\\csv_file\\nownews\\news_content_0515.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = np.random.permutation(result.shape[0])\n",
    "df = result.take(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>萬元紓困亂！馬英九「四不一沒有」曝原因：各國都發現金 | 政治 | NOWnews 今日新聞</td>\n",
       "      <td>受新冠肺炎疫情影響，台灣不少產業、勞工生計受到衝擊，政府的紓困計畫也陸續上路，希望幫助民眾度...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>陳建仁「擇優」放棄卸任禮遇？名醫神分析　1.7萬人讚爆 | 政治 | NOWnews 今日新聞</td>\n",
       "      <td>陳建仁副總統日前向蔡英文總統表示，在 520 卸任後，將應中央研究院邀請，回任中研院特聘研究...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>巷仔內／排椅子也是專業！蘇貞昌內閣拍畢業照的座位學 | 政治 | NOWnews 今日新聞</td>\n",
       "      <td>蔡政府下週即將邁入第二任期，昨（14）日上午，行政院長蘇貞昌依照憲政慣例率領內閣總辭，並且在...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>金管會主委顧立雄不續任  副主委黃天牧升任主委 | 政治 | NOWnews 今日新聞</td>\n",
       "      <td>行政院長蘇貞昌啟動內閣改組徵詢，據了解，金管會主委顧立雄將不續任、另有安排，主委一職由現任常...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>確定了！蔡英文宣布林錫耀接任黨秘書長 | 政治 | NOWnews 今日新聞</td>\n",
       "      <td>5月20日除了總統就職外，蔡英文也將重新接掌黨主席職務。而蔡英文也在今（14）晚宣布，由前行...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>慈濟感謝防疫前線員警　贈北港警蔬食便當 | 地方 | NOWnews 今日新聞</td>\n",
       "      <td>新冠肺炎疫情雖有趨緩，但為感謝一直站在第一線協助防疫工作的員警辛勞，佛教慈濟基金會北港辦事處...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>新冠疫情減緩　幼兒疫苗接種應按時 | 地方 | NOWnews 今日新聞</td>\n",
       "      <td>新冠肺炎疫情近期雖已有所減緩，但部分家長為減少出入醫療院所的機會，而延遲了幼兒疫苗接種的時程...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>「高雄」城市更名百年　高市總動員系列活動無限精彩 | 地方 | NOWnews 今日新聞</td>\n",
       "      <td>「高雄」這個名字已經有100年的歲月，為慶祝高雄城市之名誕生百年，市府規劃「高雄100無限精...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>「早安博物館」活動　十三行博物館遇見護理師、汪星人 | 地方 | NOWnews 今日新聞</td>\n",
       "      <td>新北市立十三行博物館推出全新「早安博物館」系列活動，於每月第一個星期日提早1小時開館。並因應...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>中市國民運動中心、市府所屬機關　逐步洽公解禁 | 地方 | NOWnews 今日新聞</td>\n",
       "      <td>新冠肺炎疫情趨緩，台中繼宣佈社區關懷據點恢復「健康促進活動」、親子館開放、校園「假日」開放民...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     萬元紓困亂！馬英九「四不一沒有」曝原因：各國都發現金 | 政治 | NOWnews 今日新聞   \n",
       "1    陳建仁「擇優」放棄卸任禮遇？名醫神分析　1.7萬人讚爆 | 政治 | NOWnews 今日新聞   \n",
       "2      巷仔內／排椅子也是專業！蘇貞昌內閣拍畢業照的座位學 | 政治 | NOWnews 今日新聞   \n",
       "3        金管會主委顧立雄不續任  副主委黃天牧升任主委 | 政治 | NOWnews 今日新聞   \n",
       "4             確定了！蔡英文宣布林錫耀接任黨秘書長 | 政治 | NOWnews 今日新聞   \n",
       "..                                               ...   \n",
       "233          慈濟感謝防疫前線員警　贈北港警蔬食便當 | 地方 | NOWnews 今日新聞   \n",
       "234             新冠疫情減緩　幼兒疫苗接種應按時 | 地方 | NOWnews 今日新聞   \n",
       "235     「高雄」城市更名百年　高市總動員系列活動無限精彩 | 地方 | NOWnews 今日新聞   \n",
       "236    「早安博物館」活動　十三行博物館遇見護理師、汪星人 | 地方 | NOWnews 今日新聞   \n",
       "237       中市國民運動中心、市府所屬機關　逐步洽公解禁 | 地方 | NOWnews 今日新聞   \n",
       "\n",
       "                                               content  news_label  \n",
       "0    受新冠肺炎疫情影響，台灣不少產業、勞工生計受到衝擊，政府的紓困計畫也陸續上路，希望幫助民眾度...           0  \n",
       "1    陳建仁副總統日前向蔡英文總統表示，在 520 卸任後，將應中央研究院邀請，回任中研院特聘研究...           0  \n",
       "2    蔡政府下週即將邁入第二任期，昨（14）日上午，行政院長蘇貞昌依照憲政慣例率領內閣總辭，並且在...           0  \n",
       "3    行政院長蘇貞昌啟動內閣改組徵詢，據了解，金管會主委顧立雄將不續任、另有安排，主委一職由現任常...           0  \n",
       "4    5月20日除了總統就職外，蔡英文也將重新接掌黨主席職務。而蔡英文也在今（14）晚宣布，由前行...           0  \n",
       "..                                                 ...         ...  \n",
       "233  新冠肺炎疫情雖有趨緩，但為感謝一直站在第一線協助防疫工作的員警辛勞，佛教慈濟基金會北港辦事處...          13  \n",
       "234  新冠肺炎疫情近期雖已有所減緩，但部分家長為減少出入醫療院所的機會，而延遲了幼兒疫苗接種的時程...          13  \n",
       "235  「高雄」這個名字已經有100年的歲月，為慶祝高雄城市之名誕生百年，市府規劃「高雄100無限精...          13  \n",
       "236  新北市立十三行博物館推出全新「早安博物館」系列活動，於每月第一個星期日提早1小時開館。並因應...          13  \n",
       "237  新冠肺炎疫情趨緩，台中繼宣佈社區關懷據點恢復「健康促進活動」、親子館開放、校園「假日」開放民...          13  \n",
       "\n",
       "[238 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_1 = \"\".join(list(df.loc[df.loc[:,\"news_label\"] == 0,\"content\"]))\n",
    "period_2 = \" \".join(list(df.loc[df.loc[:,\"news_label\"] == 1,\"content\"]))\n",
    "period_3 = \" \".join(list(df.loc[df.loc[:,\"news_label\"] == 2,\"content\"]))\n",
    "period_4 = \" \".join(list(df.loc[df.loc[:,\"news_label\"] == 3,\"content\"]))\n",
    "period_5 = \" \".join(list(df.loc[df.loc[:,\"news_label\"] == 4,\"content\"]))\n",
    "period_6 = \" \".join(list(df.loc[df.loc[:,\"news_label\"] == 5,\"content\"]))\n",
    "period_7 = \" \".join(list(df.loc[0]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('柯文哲')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut_result(text, stopWordsPath):\n",
    "    \"\"\"\n",
    "    实现效果: 输入一段文本，返回分词后，重新组成的文本(需要给出停用词的路径)\n",
    "    input:  \n",
    "        text: 一段由文本组成的字符串 \n",
    "        stopWordPath: 停用词文件路径\n",
    "    output: \n",
    "        cutted_concated: 分词后，重新组成的长字符串\n",
    "    \"\"\"\n",
    "    # 导入停用词表\n",
    "    line = open(stopWordsPath, encoding=\"utf8\").readlines()\n",
    "    #stopwords = line.split(\",\")\n",
    "    stopwords = []\n",
    "    for lines in line:\n",
    "        stopwords.append(lines.replace(\"\\n\",\"\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 构造数字、字母pat\n",
    "    pat = re.compile(\"[a-z0-9A-Z]+\")\n",
    "    result = []\n",
    "    seg_list_1 = jieba.cut(text, cut_all=False) # 使用jieba进行分词\n",
    "    \n",
    "    for seg in seg_list_1:        # 对分词结束后获得的list重新拼接\n",
    "        pat_find = re.search(pat, seg)\n",
    "        if seg not in stopwords and pat_find is None:  # 过滤掉停词和全部是pat的词汇\n",
    "            seg = ''.join(seg.split()) #  首先对空格进行处理\n",
    "            if (seg != '' and seg != \"\\n\" and seg != \"\\n\\n\") :\n",
    "                result.append(seg)\n",
    "        cutted_concated = \" \".join(result)\n",
    "    return cutted_concated\n",
    "\n",
    "concate_1 = get_cut_result(period_1, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_2 = get_cut_result(period_2, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_3 = get_cut_result(period_3, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_4 = get_cut_result(period_4, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_5 = get_cut_result(period_5, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_6 = get_cut_result(period_6, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")\n",
    "concate_7 = get_cut_result(period_7, r\"c:\\Users\\yhchou\\bert_case\\stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(\"[a-z0-9A-Z]+\")\n",
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(concate_1)\n",
    "corpus.append(concate_2)\n",
    "corpus.append(concate_3)\n",
    "corpus.append(concate_4)\n",
    "corpus.append(concate_5)\n",
    "corpus.append(concate_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba.add_word('鋼鐵韓粉')\n",
    "jieba.add_word('韓粉')\n",
    "jieba.add_word('鋼鐵')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个CountVectorizer类\n",
    "# 对corpus里的文本计算tf idf值\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "vectorizer = CountVectorizer()    \n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "word = vectorizer.get_feature_names() #所有文本的关键字\n",
    "weight = tfidf.toarray()              #对应的tfidf矩阵\n",
    "\n",
    "score_dict = {}\n",
    "for i in range(len(corpus)):\n",
    "    scores = weight[i]\n",
    "    score_dict[str(i)] = {key:value for (key,value) in zip(scores,word)}\n",
    "    # score_dict['0'] 这里的0表示的第几阶段\n",
    "\n",
    "top_30 = sorted(score_dict[\"0\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"0\"][top_30[i]] + \":\" + str(top_30[i]))\n",
    "    \n",
    "    \n",
    "for i in range(len(weight)):#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重\n",
    "    print (u\"-------这里输出第\",i,u\"类文本的词语tf-idf权重------\")\n",
    "    for j in range(len(word)):\n",
    "        print (word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# politics : 政治"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"0\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"0\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clips : 影音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"1\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"1\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show : 節目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"2\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"2\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entertainment : 娛樂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"3\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"3\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column : 焦點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"4\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"4\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forum-2 : 觀點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = sorted(score_dict[\"5\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"5\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print((word))     #关键词的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将各个阶段的tf idf值、关键词等组合成一个字典\n",
    "score_dict = {}\n",
    "for i in range(len(corpus)):\n",
    "    scores = weight[i]\n",
    "    score_dict[str(i)] = {key:value for (key,value) in zip(scores,word)}\n",
    "    # score_dict['0'] 这里的0表示的第几阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出各个阶段tf idf值排名前n的关键词\n",
    "# 第一阶段的前10个关键词\n",
    "top_30 = sorted(score_dict[\"1\"].keys(),reverse=True)[0:30]\n",
    "for i in range(30):\n",
    "    print(score_dict[\"1\"][top_30[i]] + \":\" + str(top_30[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['This is the first document.',\n",
    "           'This document is the second document.',\n",
    "           'And this is the third one.',\n",
    "           'Is this the first document?']\n",
    "#语料\n",
    "#corpus = news_article\n",
    "#将文本中的词语转换为词频矩阵\n",
    "vectorizer = CountVectorizer()\n",
    "#计算个词语出现的次数\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "#获取词袋中所有文本关键词\n",
    "word = vectorizer.get_feature_names()\n",
    "print(word)\n",
    "#查看词频结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_cut_result(df.loc[0]['content'], r\"C:\\Users\\yhchou\\py37_new\\Lib\\site-packages\\jieba\\stopwords.txt\")\n",
    "corpuss = []\n",
    "corpuss.append(test)\n",
    "\n",
    "\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpuss))\n",
    "word = vectorizer.get_feature_names() #所有文本的关键字\n",
    "weight = tfidf.toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[df.loc[0]['content'],#第一类文本切词后的结果，词之间以空格隔开\n",
    "        df.loc[0]['content'],#第二类文本的切词结果\n",
    "        \"小明 硕士 毕业 与 中国 科学院\",#第三类文本的切词结果\n",
    "        \"我 爱 北京 天安门\"]#第四类文本的切词结果\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "transformer=TfidfTransformer()#该类会统计每个词语的tf-idf权值\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))#第一个fit_transform是计算tf-idf，第二个fit_transform是将文本转为词频矩阵\n",
    "word=vectorizer.get_feature_names()#获取词袋模型中的所有词语\n",
    "weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "for i in range(len(weight)):#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重\n",
    "    print (u\"-------这里输出第\",i,u\"类文本的词语tf-idf权重------\")\n",
    "    for j in range(len(word)):\n",
    "        print (word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = ['This is the first document.', 'This is the second document.']\n",
    "X_test = ['This is the first document.']\n",
    "vectorizer = TfidfVectorizer()\n",
    "# 用X_train数据来fit\n",
    "vectorizer.fit(X_train)\n",
    "# 得到tfidf的矩阵\n",
    "tfidf_train = vectorizer.transform(X_train)\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_train.toarray()\n",
    "tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = ['This is the first document.', 'This is the second document.']\n",
    "X_test = ['This is the third document.']\n",
    "vectorizer = TfidfVectorizer()\n",
    "# 用X_train数据来fit\n",
    "vectorizer.fit(X_train)\n",
    "# 得到tfidf的矩阵\n",
    "tfidf_train = vectorizer.transform(X_train)\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DB_content_csv():\n",
    "    df_train = pd.read_csv(r\"C:\\Users\\yhchou\\bert_case\\news_content.csv\")\n",
    "    sampler = np.random.permutation(230)\n",
    "    df_train = df_train.take(sampler)\n",
    "    news_content = df_train['content'].tolist()\n",
    "    return news_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_DB_content_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMsum = 0\n",
    "for i in range(len(a)):\n",
    "    NUMsum += len(a[i])\n",
    "\n",
    "print(NUMsum/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37new",
   "language": "python",
   "name": "py37_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
