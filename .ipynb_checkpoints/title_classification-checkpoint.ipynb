{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "#configuration = BertConfig(hidden_size=768)\n",
    "\n",
    "model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\yhchou\\bert_case\\news_content.csv\")\n",
    "sampler = np.random.permutation(230)\n",
    "df_train = df_train.take(sampler)\n",
    "df_train.drop_duplicates(subset=\"title\",\n",
    "                     keep=False, inplace=True)\n",
    "news_content = df_train['title'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "news_title = []\n",
    "dic = ['politics','clips','show','entertainment','column','forum-2','global','sport','house2','finance','chinaindex',\n",
    "       'novelty','life','local']\n",
    "for i in range(len(dic)):\n",
    "    url ='https://gcs-static-json-lb.nownews.com/api/v1/cat/'+ dic[i] +'.json'\n",
    "    ua = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\"\n",
    "\n",
    "    with requests.request('GET', url, headers={'User-agent': ua}) as res:\n",
    "        content = res.text  # 获取HTML的内容\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    newDictionary = json.loads(str(soup))\n",
    "    for i in range(len(newDictionary['data']['newsList'])):\n",
    "        news_title.append(newDictionary['data']['newsList'][i]['postTitle'])\n",
    "    l2 = list(set(news_title))\n",
    "    #print(len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = open(r'c:\\Users\\yhchou\\bert_case\\stopwords.txt', encoding=\"utf8\").readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '--',\n",
       " '.',\n",
       " '..',\n",
       " '...',\n",
       " '......',\n",
       " '...................',\n",
       " './',\n",
       " '.一',\n",
       " '记者',\n",
       " '数',\n",
       " '年',\n",
       " '月',\n",
       " '日',\n",
       " '时',\n",
       " '分',\n",
       " '秒',\n",
       " '/',\n",
       " '//',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '://',\n",
       " '::',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '>>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'Lex',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '【',\n",
       " '】',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'exp',\n",
       " 'sub',\n",
       " 'sup',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '~~~~',\n",
       " '·',\n",
       " '×',\n",
       " '×××',\n",
       " 'Δ',\n",
       " 'Ψ',\n",
       " 'γ',\n",
       " 'μ',\n",
       " 'φ',\n",
       " 'φ．',\n",
       " 'В',\n",
       " '—',\n",
       " '——',\n",
       " '———',\n",
       " '‘',\n",
       " '’',\n",
       " '’‘',\n",
       " '“',\n",
       " '”',\n",
       " '”，',\n",
       " '…',\n",
       " '……',\n",
       " '…………………………………………………③',\n",
       " '′∈',\n",
       " '′｜',\n",
       " '℃',\n",
       " 'Ⅲ',\n",
       " '↑',\n",
       " '→',\n",
       " '∈［',\n",
       " '∪φ∈',\n",
       " '≈',\n",
       " '①',\n",
       " '②',\n",
       " '②ｃ',\n",
       " '③',\n",
       " '③］',\n",
       " '④',\n",
       " '⑤',\n",
       " '⑥',\n",
       " '⑦',\n",
       " '⑧',\n",
       " '⑨',\n",
       " '⑩',\n",
       " '──',\n",
       " '■',\n",
       " '▲',\n",
       " '\\u3000',\n",
       " '、',\n",
       " '。',\n",
       " '〈',\n",
       " '〉',\n",
       " '《',\n",
       " '》',\n",
       " '》），',\n",
       " '」',\n",
       " '『',\n",
       " '』',\n",
       " '〔',\n",
       " '〕',\n",
       " '〕〔',\n",
       " '㈧',\n",
       " '一',\n",
       " '一.',\n",
       " '一一',\n",
       " '一下',\n",
       " '一个',\n",
       " '一些',\n",
       " '一何',\n",
       " '一切',\n",
       " '一则',\n",
       " '一则通过',\n",
       " '一天',\n",
       " '一定',\n",
       " '一方面',\n",
       " '一旦',\n",
       " '一时',\n",
       " '一来',\n",
       " '一样',\n",
       " '一次',\n",
       " '一片',\n",
       " '一番',\n",
       " '一直',\n",
       " '一致',\n",
       " '一般',\n",
       " '一起',\n",
       " '一转眼',\n",
       " '一边',\n",
       " '一面',\n",
       " '男子',\n",
       " '女子',\n",
       " '七',\n",
       " '万一',\n",
       " '三',\n",
       " '三天两头',\n",
       " '三番两次',\n",
       " '三番五次',\n",
       " '上',\n",
       " '上下',\n",
       " '上升',\n",
       " '上去',\n",
       " '上来',\n",
       " '上述',\n",
       " '上面',\n",
       " '下',\n",
       " '下列',\n",
       " '下去',\n",
       " '下来',\n",
       " '下面',\n",
       " '不',\n",
       " '不一',\n",
       " '不下',\n",
       " '不久',\n",
       " '不了',\n",
       " '不亦乐乎',\n",
       " '不仅',\n",
       " '不仅...而且',\n",
       " '不仅仅',\n",
       " '不仅仅是',\n",
       " '不会',\n",
       " '不但',\n",
       " '不但...而且',\n",
       " '不光',\n",
       " '不免',\n",
       " '不再',\n",
       " '不力',\n",
       " '不单',\n",
       " '不变',\n",
       " '不只',\n",
       " '不可',\n",
       " '不可开交',\n",
       " '不可抗拒',\n",
       " '不同',\n",
       " '不外',\n",
       " '不外乎',\n",
       " '不够',\n",
       " '不大',\n",
       " '不如',\n",
       " '不妨',\n",
       " '不定',\n",
       " '不对',\n",
       " '不少',\n",
       " '不尽',\n",
       " '不尽然',\n",
       " '不巧',\n",
       " '不已',\n",
       " '不常',\n",
       " '不得',\n",
       " '不得不',\n",
       " '不得了',\n",
       " '不得已',\n",
       " '不必',\n",
       " '不怎么',\n",
       " '不怕',\n",
       " '不惟',\n",
       " '不成',\n",
       " '不拘',\n",
       " '不择手段',\n",
       " '不敢',\n",
       " '不料',\n",
       " '不断',\n",
       " '不日',\n",
       " '不时',\n",
       " '不是',\n",
       " '不曾',\n",
       " '不止',\n",
       " '不止一次',\n",
       " '不比',\n",
       " '不消',\n",
       " '不满',\n",
       " '不然',\n",
       " '不然的话',\n",
       " '不特',\n",
       " '不独',\n",
       " '不由得',\n",
       " '不知不觉',\n",
       " '不管',\n",
       " '不管怎样',\n",
       " '不经意',\n",
       " '不胜',\n",
       " '不能',\n",
       " '不能不',\n",
       " '不至于',\n",
       " '不若',\n",
       " '不要',\n",
       " '不论',\n",
       " '不起',\n",
       " '不足',\n",
       " '不过',\n",
       " '不迭',\n",
       " '不问',\n",
       " '不限',\n",
       " '与',\n",
       " '与其',\n",
       " '与其说',\n",
       " '与否',\n",
       " '与此同时',\n",
       " '专门',\n",
       " '且',\n",
       " '且不说',\n",
       " '且说',\n",
       " '两者',\n",
       " '严格',\n",
       " '严重',\n",
       " '个',\n",
       " '个人',\n",
       " '个别',\n",
       " '中小',\n",
       " '中间',\n",
       " '丰富',\n",
       " '串行',\n",
       " '临',\n",
       " '临到',\n",
       " '为',\n",
       " '为主',\n",
       " '为了',\n",
       " '为什么',\n",
       " '为什麽',\n",
       " '为何',\n",
       " '为止',\n",
       " '为此',\n",
       " '为着',\n",
       " '主张',\n",
       " '主要',\n",
       " '举凡',\n",
       " '举行',\n",
       " '乃',\n",
       " '乃至',\n",
       " '乃至于',\n",
       " '么',\n",
       " '之',\n",
       " '之一',\n",
       " '之前',\n",
       " '之后',\n",
       " '之後',\n",
       " '之所以',\n",
       " '之类',\n",
       " '乌乎',\n",
       " '乎',\n",
       " '乒',\n",
       " '乘',\n",
       " '乘势',\n",
       " '乘机',\n",
       " '乘胜',\n",
       " '乘虚',\n",
       " '乘隙',\n",
       " '九',\n",
       " '也',\n",
       " '也好',\n",
       " '也就是说',\n",
       " '也是',\n",
       " '也罢',\n",
       " '了',\n",
       " '了解',\n",
       " '争取',\n",
       " '二',\n",
       " '二来',\n",
       " '二话不说',\n",
       " '二话没说',\n",
       " '于',\n",
       " '于是',\n",
       " '于是乎',\n",
       " '云云',\n",
       " '云尔',\n",
       " '互',\n",
       " '互相',\n",
       " '五',\n",
       " '些',\n",
       " '交口',\n",
       " '亦',\n",
       " '产生',\n",
       " '亲口',\n",
       " '亲手',\n",
       " '亲眼',\n",
       " '亲自',\n",
       " '亲身',\n",
       " '人',\n",
       " '人人',\n",
       " '人们',\n",
       " '人家',\n",
       " '人民',\n",
       " '什么',\n",
       " '什么样',\n",
       " '什麽',\n",
       " '仅',\n",
       " '仅仅',\n",
       " '今',\n",
       " '今后',\n",
       " '今天',\n",
       " '今年',\n",
       " '今後',\n",
       " '介于',\n",
       " '仍',\n",
       " '仍旧',\n",
       " '仍然',\n",
       " '从',\n",
       " '从不',\n",
       " '从严',\n",
       " '从中',\n",
       " '从事',\n",
       " '从今以后',\n",
       " '从优',\n",
       " '从古到今',\n",
       " '从古至今',\n",
       " '从头',\n",
       " '从宽',\n",
       " '从小',\n",
       " '从新',\n",
       " '从无到有',\n",
       " '从早到晚',\n",
       " '从未',\n",
       " '从来',\n",
       " '从此',\n",
       " '从此以后',\n",
       " '从而',\n",
       " '从轻',\n",
       " '从速',\n",
       " '从重',\n",
       " '他',\n",
       " '他人',\n",
       " '他们',\n",
       " '他是',\n",
       " '他的',\n",
       " '代替',\n",
       " '以',\n",
       " '以上',\n",
       " '以下',\n",
       " '以为',\n",
       " '以便',\n",
       " '以免',\n",
       " '以前',\n",
       " '以及',\n",
       " '以后',\n",
       " '以外',\n",
       " '以後',\n",
       " '以故',\n",
       " '以期',\n",
       " '以来',\n",
       " '以至',\n",
       " '以至于',\n",
       " '以致',\n",
       " '们',\n",
       " '任',\n",
       " '任何',\n",
       " '任凭',\n",
       " '任务',\n",
       " '企图',\n",
       " '伙同',\n",
       " '会',\n",
       " '伟大',\n",
       " '传',\n",
       " '传说',\n",
       " '传闻',\n",
       " '似乎',\n",
       " '似的',\n",
       " '但',\n",
       " '但凡',\n",
       " '但愿',\n",
       " '但是',\n",
       " '何',\n",
       " '何乐而不为',\n",
       " '何以',\n",
       " '何况',\n",
       " '何处',\n",
       " '何妨',\n",
       " '何尝',\n",
       " '何必',\n",
       " '何时',\n",
       " '何止',\n",
       " '何苦',\n",
       " '何须',\n",
       " '余外',\n",
       " '作为',\n",
       " '你',\n",
       " '你们',\n",
       " '你是',\n",
       " '你的',\n",
       " '使',\n",
       " '使得',\n",
       " '使用',\n",
       " '例如',\n",
       " '依',\n",
       " '依据',\n",
       " '依照',\n",
       " '依靠',\n",
       " '便',\n",
       " '便于',\n",
       " '促进',\n",
       " '保持',\n",
       " '保管',\n",
       " '保险',\n",
       " '俺',\n",
       " '俺们',\n",
       " '倍加',\n",
       " '倍感',\n",
       " '倒不如',\n",
       " '倒不如说',\n",
       " '倒是',\n",
       " '倘',\n",
       " '倘使',\n",
       " '倘或',\n",
       " '倘然',\n",
       " '倘若',\n",
       " '借',\n",
       " '借以',\n",
       " '借此',\n",
       " '假使',\n",
       " '假如',\n",
       " '假若',\n",
       " '偏偏',\n",
       " '做到',\n",
       " '偶尔',\n",
       " '偶而',\n",
       " '傥然',\n",
       " '像',\n",
       " '儿',\n",
       " '允许',\n",
       " '元／吨',\n",
       " '充其极',\n",
       " '充其量',\n",
       " '充分',\n",
       " '先不先',\n",
       " '先后',\n",
       " '先後',\n",
       " '先生',\n",
       " '光',\n",
       " '光是',\n",
       " '全体',\n",
       " '全力',\n",
       " '全年',\n",
       " '全然',\n",
       " '全身心',\n",
       " '全部',\n",
       " '全都',\n",
       " '全面',\n",
       " '八',\n",
       " '八成',\n",
       " '公然',\n",
       " '六',\n",
       " '兮',\n",
       " '共',\n",
       " '共同',\n",
       " '共总',\n",
       " '关于',\n",
       " '其',\n",
       " '其一',\n",
       " '其中',\n",
       " '其二',\n",
       " '其他',\n",
       " '其余',\n",
       " '其后',\n",
       " '其它',\n",
       " '其实',\n",
       " '其次',\n",
       " '具体',\n",
       " '具体地说',\n",
       " '具体来说',\n",
       " '具体说来',\n",
       " '具有',\n",
       " '兼之',\n",
       " '内',\n",
       " '再',\n",
       " '再其次',\n",
       " '再则',\n",
       " '再有',\n",
       " '再次',\n",
       " '再者',\n",
       " '再者说',\n",
       " '再说',\n",
       " '冒',\n",
       " '冲',\n",
       " '决不',\n",
       " '决定',\n",
       " '决非',\n",
       " '况且',\n",
       " '准备',\n",
       " '凑巧',\n",
       " '凝神',\n",
       " '几',\n",
       " '几乎',\n",
       " '几度',\n",
       " '几时',\n",
       " '几番',\n",
       " '几经',\n",
       " '凡',\n",
       " '凡是',\n",
       " '凭',\n",
       " '凭借',\n",
       " '出',\n",
       " '出于',\n",
       " '出去',\n",
       " '出来',\n",
       " '出现',\n",
       " '分别',\n",
       " '分头',\n",
       " '分期',\n",
       " '分期分批',\n",
       " '切',\n",
       " '切不可',\n",
       " '切切',\n",
       " '切勿',\n",
       " '切莫',\n",
       " '则',\n",
       " '则甚',\n",
       " '刚',\n",
       " '刚好',\n",
       " '刚巧',\n",
       " '刚才',\n",
       " '初',\n",
       " '别',\n",
       " '别人',\n",
       " '别处',\n",
       " '别是',\n",
       " '别的',\n",
       " '别管',\n",
       " '别说',\n",
       " '到',\n",
       " '到了儿',\n",
       " '到处',\n",
       " '到头',\n",
       " '到头来',\n",
       " '到底',\n",
       " '到目前为止',\n",
       " '前后',\n",
       " '前此',\n",
       " '前者',\n",
       " '前进',\n",
       " '前面',\n",
       " '加上',\n",
       " '加之',\n",
       " '加以',\n",
       " '加入',\n",
       " '加强',\n",
       " '动不动',\n",
       " '动辄',\n",
       " '勃然',\n",
       " '匆匆',\n",
       " '十分',\n",
       " '千',\n",
       " '千万',\n",
       " '千万千万',\n",
       " '半',\n",
       " '单',\n",
       " '单单',\n",
       " '单纯',\n",
       " '即',\n",
       " '即令',\n",
       " '即使',\n",
       " '即便',\n",
       " '即刻',\n",
       " '即如',\n",
       " '即将',\n",
       " '即或',\n",
       " '即是说',\n",
       " '即若',\n",
       " '却',\n",
       " '却不',\n",
       " '历',\n",
       " '原来',\n",
       " '去',\n",
       " '又',\n",
       " '又及',\n",
       " '及',\n",
       " '及其',\n",
       " '及时',\n",
       " '及至',\n",
       " '双方',\n",
       " '反之',\n",
       " '反之亦然',\n",
       " '反之则',\n",
       " '反倒',\n",
       " '反倒是',\n",
       " '反应',\n",
       " '反手',\n",
       " '反映',\n",
       " '反而',\n",
       " '反过来',\n",
       " '反过来说',\n",
       " '取得',\n",
       " '取道',\n",
       " '受到',\n",
       " '变成',\n",
       " '古来',\n",
       " '另',\n",
       " '另一个',\n",
       " '另一方面',\n",
       " '另外',\n",
       " '另悉',\n",
       " '另方面',\n",
       " '另行',\n",
       " '只',\n",
       " '只当',\n",
       " '只怕',\n",
       " '只是',\n",
       " '只有',\n",
       " '只消',\n",
       " '只要',\n",
       " '只限',\n",
       " '叫',\n",
       " '叫做',\n",
       " '召开',\n",
       " '叮咚',\n",
       " '叮当',\n",
       " '可',\n",
       " '可以',\n",
       " '可好',\n",
       " '可是',\n",
       " '可能',\n",
       " '可见',\n",
       " '各',\n",
       " '各个',\n",
       " '各人',\n",
       " '各位',\n",
       " '各地',\n",
       " '各式',\n",
       " '各种',\n",
       " '各级',\n",
       " '各自',\n",
       " '合理',\n",
       " '同',\n",
       " '同一',\n",
       " '同时',\n",
       " '同样',\n",
       " '后',\n",
       " '后来',\n",
       " '后者',\n",
       " '后面',\n",
       " '向',\n",
       " '向使',\n",
       " '向着',\n",
       " '吓',\n",
       " '吗',\n",
       " '否则',\n",
       " '吧',\n",
       " '吧哒',\n",
       " '吱',\n",
       " '呀',\n",
       " '呃',\n",
       " '呆呆地',\n",
       " '呐',\n",
       " '呕',\n",
       " '呗',\n",
       " '呜',\n",
       " '呜呼',\n",
       " '呢',\n",
       " '周围',\n",
       " '呵',\n",
       " '呵呵',\n",
       " '呸',\n",
       " '呼哧',\n",
       " '呼啦',\n",
       " '咋',\n",
       " '和',\n",
       " '咚',\n",
       " '咦',\n",
       " '咧',\n",
       " '咱',\n",
       " '咱们',\n",
       " '咳',\n",
       " '哇',\n",
       " '哈',\n",
       " '哈哈',\n",
       " '哉',\n",
       " '哎',\n",
       " '哎呀',\n",
       " '哎哟',\n",
       " '哗',\n",
       " '哗啦',\n",
       " '哟',\n",
       " '哦',\n",
       " '哩',\n",
       " '哪',\n",
       " '哪个',\n",
       " '哪些',\n",
       " '哪儿',\n",
       " '哪天',\n",
       " '哪年',\n",
       " '哪怕',\n",
       " '哪样',\n",
       " '哪边',\n",
       " '哪里',\n",
       " '哼',\n",
       " '哼唷',\n",
       " '唉',\n",
       " '唯有',\n",
       " '啊',\n",
       " '啊呀',\n",
       " '啊哈',\n",
       " '啊哟',\n",
       " '啐',\n",
       " '啥',\n",
       " '啦',\n",
       " '啪达',\n",
       " '啷当',\n",
       " '喀',\n",
       " '喂',\n",
       " '喏',\n",
       " '喔唷',\n",
       " '喽',\n",
       " '嗡',\n",
       " '嗡嗡',\n",
       " '嗬',\n",
       " '嗯',\n",
       " '嗳',\n",
       " '嘎',\n",
       " '嘎嘎',\n",
       " '嘎登',\n",
       " '嘘',\n",
       " '嘛',\n",
       " '嘻',\n",
       " '嘿',\n",
       " '嘿嘿',\n",
       " '四',\n",
       " '因',\n",
       " '因为',\n",
       " '因了',\n",
       " '因此',\n",
       " '因着',\n",
       " '因而',\n",
       " '固',\n",
       " '固然',\n",
       " '在',\n",
       " '在下',\n",
       " '在于',\n",
       " '地',\n",
       " '均',\n",
       " '坚决',\n",
       " '坚持',\n",
       " '基于',\n",
       " '基本',\n",
       " '基本上',\n",
       " '处在',\n",
       " '处处',\n",
       " '处理',\n",
       " '复杂',\n",
       " '多',\n",
       " '多么',\n",
       " '多亏',\n",
       " '多多',\n",
       " '多多少少',\n",
       " '多多益善',\n",
       " '多少',\n",
       " '多年前',\n",
       " '多年来',\n",
       " '多数',\n",
       " '多次',\n",
       " '够瞧的',\n",
       " '大',\n",
       " '大不了',\n",
       " '大举',\n",
       " '大事',\n",
       " '大体',\n",
       " '大体上',\n",
       " '大凡',\n",
       " '大力',\n",
       " '大多',\n",
       " '大多数',\n",
       " '大大',\n",
       " '大家',\n",
       " '大张旗鼓',\n",
       " '大批',\n",
       " '大抵',\n",
       " '大概',\n",
       " '大略',\n",
       " '大约',\n",
       " '大致',\n",
       " '大都',\n",
       " '大量',\n",
       " '大面儿上',\n",
       " '失去',\n",
       " '奇',\n",
       " '奈',\n",
       " '奋勇',\n",
       " '她',\n",
       " '她们',\n",
       " '她是',\n",
       " '她的',\n",
       " '好',\n",
       " '好在',\n",
       " '好的',\n",
       " '好象',\n",
       " '如',\n",
       " '如上',\n",
       " '如上所述',\n",
       " '如下',\n",
       " '如今',\n",
       " '如何',\n",
       " '如其',\n",
       " '如前所述',\n",
       " '如同',\n",
       " '如常',\n",
       " '如是',\n",
       " '如期',\n",
       " '如果',\n",
       " '如次',\n",
       " '如此',\n",
       " '如此等等',\n",
       " '如若',\n",
       " '始而',\n",
       " '姑且',\n",
       " '存在',\n",
       " '存心',\n",
       " '孰料',\n",
       " '孰知',\n",
       " '宁',\n",
       " '宁可',\n",
       " '宁愿',\n",
       " '宁肯',\n",
       " '它',\n",
       " '它们',\n",
       " '它们的',\n",
       " '它是',\n",
       " '它的',\n",
       " '安全',\n",
       " '完全',\n",
       " '完成',\n",
       " '定',\n",
       " '实现',\n",
       " '实际',\n",
       " '宣布',\n",
       " '容易',\n",
       " '密切',\n",
       " '对',\n",
       " '对于',\n",
       " '对应',\n",
       " '对待',\n",
       " '对方',\n",
       " '对比',\n",
       " '将',\n",
       " '将才',\n",
       " '将要',\n",
       " '将近',\n",
       " '小',\n",
       " '少数',\n",
       " '尔',\n",
       " '尔后',\n",
       " '尔尔',\n",
       " '尔等',\n",
       " '尚且',\n",
       " '尤其',\n",
       " '就',\n",
       " '就地',\n",
       " '就是',\n",
       " '就是了',\n",
       " '就是说',\n",
       " '就此',\n",
       " '就算',\n",
       " '就要',\n",
       " '尽',\n",
       " '尽可能',\n",
       " '尽如人意',\n",
       " '尽心尽力',\n",
       " '尽心竭力',\n",
       " '尽快',\n",
       " '尽早',\n",
       " '尽然',\n",
       " '尽管',\n",
       " '尽管如此',\n",
       " '尽量',\n",
       " '局外',\n",
       " '居然',\n",
       " '届时',\n",
       " '属于',\n",
       " '屡',\n",
       " '屡屡',\n",
       " '屡次',\n",
       " '屡次三番',\n",
       " '岂',\n",
       " '岂但',\n",
       " '岂止',\n",
       " '岂非',\n",
       " '川流不息',\n",
       " '左右',\n",
       " '巨大',\n",
       " '巩固',\n",
       " '差一点',\n",
       " '差不多',\n",
       " '己',\n",
       " '已',\n",
       " '已矣',\n",
       " '已经',\n",
       " '巴',\n",
       " '巴巴',\n",
       " '带',\n",
       " '帮助',\n",
       " '常',\n",
       " '常常',\n",
       " '常言说',\n",
       " '常言说得好',\n",
       " '常言道',\n",
       " '平素',\n",
       " '年复一年',\n",
       " '并',\n",
       " '并不',\n",
       " '并不是',\n",
       " '并且',\n",
       " '并排',\n",
       " '并无',\n",
       " '并没',\n",
       " '并没有',\n",
       " '并肩',\n",
       " '并非',\n",
       " '广大',\n",
       " '广泛',\n",
       " '应当',\n",
       " '应用',\n",
       " '应该',\n",
       " '庶乎',\n",
       " '庶几',\n",
       " '开外',\n",
       " '开始',\n",
       " '开展',\n",
       " '引起',\n",
       " '弗',\n",
       " '弹指之间',\n",
       " '强烈',\n",
       " '强调',\n",
       " '归',\n",
       " '归根到底',\n",
       " '归根结底',\n",
       " '归齐',\n",
       " '当',\n",
       " '当下',\n",
       " '当中',\n",
       " '当儿',\n",
       " '当前',\n",
       " '当即',\n",
       " '当口儿',\n",
       " '当地',\n",
       " '当场',\n",
       " '当头',\n",
       " '当庭',\n",
       " '当时',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "for lines in line:\n",
    "    stopwords.append(lines.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n"
     ]
    }
   ],
   "source": [
    "a = ['太可怕了!']\n",
    "b = ['!','?']\n",
    "a[0]\n",
    "if a not in b:\n",
    "    print('fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "\n",
    "    tokenized_text = [\"[CLS]\"]\n",
    "    tokens_a = tokenizer.tokenize(text)\n",
    "    tokenized_text += tokens_a + [\"[SEP]\"]\n",
    "\n",
    "    # tokenized_text = tokenizer.tokenize(text) #分字\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)  # 轉換成 ID\n",
    "    #print('1')\n",
    "\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "\n",
    "    # GPU & put everything on cuda\n",
    "    tokens_tensor = tokens_tensor.to('cuda:0')\n",
    "    segments_tensors = segments_tensors.to('cuda:0')\n",
    "\n",
    "\n",
    "    encoded_layers, pooled_output = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    #print(encoded_layers.shape)\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embedding =[]\n",
    "for title in l2 :\n",
    "    #print(title)\n",
    "    News_1 = encode(title)\n",
    "    News_1_vec = torch.Tensor.cpu(News_1)\n",
    "    News_1_vec = News_1_vec.detach().numpy()\n",
    "    title_embedding.append(News_1_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9979518 ,  0.9998631 ,  0.99994   ,  0.530442  , -0.35411015,\n",
       "         0.9495737 , -0.816734  , -0.8170852 ,  0.54120326, -0.99880916,\n",
       "         0.99999756,  0.9999977 , -0.76460475, -0.9818521 ,  0.99982774,\n",
       "        -0.99938995, -0.9572313 ,  0.27105916,  0.9984354 , -0.44484144,\n",
       "         0.9773618 , -0.99998873, -0.16645405, -0.8059602 , -0.8690539 ,\n",
       "         0.9979278 ,  0.9987782 , -0.45951155, -0.9999443 ,  0.99803954,\n",
       "         0.99197423,  0.9991998 ,  0.38197738, -0.99947995, -0.99782276,\n",
       "         0.5787238 , -0.61376995,  0.9933764 ,  0.88225716,  0.6925558 ,\n",
       "        -0.90191376, -0.77751046, -0.14165159, -0.9990932 ,  0.7560677 ,\n",
       "         0.9696405 , -0.9999995 , -0.9987448 ,  0.40385696,  0.9971397 ,\n",
       "        -0.9338245 , -0.9995153 ,  0.89999104, -0.9929584 , -0.97914416,\n",
       "         0.99740434, -0.99945784,  0.99815637,  0.9999995 ,  0.85250926,\n",
       "         0.9929104 ,  0.03281289,  0.1972354 , -0.9992467 ,  0.99999017,\n",
       "        -0.99971056, -0.99817294, -0.15977581,  0.99871343,  0.99999464,\n",
       "        -0.9693051 ,  0.9190695 ,  0.99999654,  0.6877049 ,  0.94332826,\n",
       "         0.99999857, -0.9954036 ,  0.8807505 , -0.999987  ,  0.9830397 ,\n",
       "         0.9999954 ,  0.9969244 , -0.98994863,  0.95681727, -0.99906844,\n",
       "        -0.99990654, -0.8645845 ,  0.9980774 ,  0.03151908,  0.993617  ,\n",
       "         0.9990253 , -0.99908644, -0.999995  ,  0.9774792 , -0.99646056,\n",
       "        -0.97528386, -0.5761883 ,  0.99413794,  0.99162   , -0.9915866 ,\n",
       "        -0.99343336,  0.84957564, -0.9999883 , -0.99993455,  0.9871144 ,\n",
       "         0.99645025,  0.94488853, -0.99868375,  0.99959826, -0.98844934,\n",
       "        -0.99999905, -0.9321933 , -0.99999964, -0.9791598 , -0.9960384 ,\n",
       "         0.99884206, -0.1632163 , -0.21073498,  0.99692255, -0.9999809 ,\n",
       "         0.95661414, -0.9926736 , -0.21678564,  0.9516515 ,  0.99653727,\n",
       "         0.9998647 ,  0.99921083, -0.89562356,  0.99996454,  0.9999643 ,\n",
       "         0.9965531 ,  0.99847746, -0.99982435,  0.96355945,  0.9569321 ,\n",
       "        -0.9919044 , -0.9908681 , -0.95294315,  0.99999744,  0.9473348 ,\n",
       "         0.99760365,  0.96735656,  0.99928415, -0.99795586,  0.9999008 ,\n",
       "        -0.99941045,  0.9998142 , -0.9999602 , -0.99636763,  0.93557   ,\n",
       "         0.97765416,  0.9999978 , -0.19627543,  0.9999376 , -0.97206086,\n",
       "        -0.96251124,  0.6308716 , -0.98562396,  0.97283447, -0.9998738 ,\n",
       "         0.96324027, -0.9902188 ,  0.90518   , -0.7083335 , -0.9999999 ,\n",
       "         0.9998681 , -0.86931175,  0.99999017,  0.9934577 , -0.9303913 ,\n",
       "        -0.9901446 , -0.99949497, -0.23210108, -0.9995402 , -0.95509154,\n",
       "         0.8099827 , -0.7706254 ,  0.99890965, -0.8582889 , -0.95202386,\n",
       "         0.9403132 , -0.86348456, -0.99966913,  0.99546856, -0.9433051 ,\n",
       "         0.9380442 ,  0.8128701 ,  0.99301654,  0.9987943 ,  0.7180989 ,\n",
       "        -0.8597248 ,  0.99990344,  0.8564355 ,  0.9826159 ,  0.9984841 ,\n",
       "         0.7259414 ,  0.600199  , -0.9852428 , -0.999956  , -0.92354125,\n",
       "         0.99994713, -0.98752767, -0.99972826,  0.95927995, -0.9999756 ,\n",
       "         0.94075966, -0.9639747 , -0.6397432 , -0.9354197 , -0.99994236,\n",
       "         0.9959598 , -0.99526703, -0.9997809 , -0.47225222,  0.43349478,\n",
       "         0.93275374, -0.9946988 ,  0.4526152 ,  0.9804593 , -0.8358637 ,\n",
       "         0.9643451 , -0.995002  , -0.99788386,  0.75915796, -0.81650037,\n",
       "         0.99840194,  0.15740019,  0.9999844 ,  0.98431534, -0.9742983 ,\n",
       "        -0.96765876,  0.9999997 , -0.2630425 , -0.9999995 ,  0.8979771 ,\n",
       "        -0.9900009 , -0.10086588,  0.999876  , -0.99926805,  0.44765034,\n",
       "         0.99994004,  0.84163743,  0.9999994 , -0.8557687 , -0.9990585 ,\n",
       "        -0.9986858 ,  0.99999416,  0.99608004,  0.9999739 , -0.99199426,\n",
       "        -0.9779447 , -0.970971  ,  0.1480048 , -0.9999883 , -0.9783546 ,\n",
       "        -0.36312422,  0.9987073 ,  0.9999822 , -0.7126461 , -0.9971173 ,\n",
       "        -0.9931006 , -0.9943014 ,  0.9999217 , -0.8692786 ,  0.99992627,\n",
       "         0.9983427 , -0.6781434 , -0.953388  ,  0.7435029 ,  0.6619779 ,\n",
       "        -0.9997888 ,  0.8826755 , -0.9999229 , -0.9941359 , -0.99928296,\n",
       "        -0.1708084 , -0.9966915 , -0.999996  ,  0.97742075,  0.99995613,\n",
       "         0.9989903 , -0.9998989 ,  0.99980915,  0.99727565, -0.04075724,\n",
       "        -0.99195665,  0.9913761 , -0.9999934 ,  0.9999987 , -0.9971656 ,\n",
       "         0.9062306 , -0.78786653, -0.98509824, -0.72865415,  0.9876822 ,\n",
       "         0.8813138 , -0.99967027, -0.74653256, -0.9982771 , -0.9594051 ,\n",
       "        -0.8361203 , -0.15860033,  0.10963283,  0.8626346 , -0.9959904 ,\n",
       "        -0.42763186, -0.77381337, -0.5670824 , -0.9986956 ,  0.4585936 ,\n",
       "         0.99999523, -0.984938  ,  0.9999917 ,  0.8157641 ,  0.99999696,\n",
       "         0.94318444, -0.9858966 ,  0.9784731 , -0.95811033, -0.66424376,\n",
       "        -0.99626493, -0.9838461 ,  0.9686757 ,  0.9651889 , -0.9875792 ,\n",
       "        -0.99840826,  0.99973   , -0.1965199 ,  0.83219606,  0.7964272 ,\n",
       "         0.05500772, -0.6043228 ,  0.927702  , -0.99574393,  0.98290545,\n",
       "        -0.99977815, -0.5062715 ,  0.99951696,  0.999842  ,  0.9987898 ,\n",
       "         0.6661978 , -0.94403213,  0.85669804, -0.99967366,  0.99953413,\n",
       "        -0.99970555,  0.99784607,  0.1407354 , -0.50860256, -0.8923808 ,\n",
       "        -0.9733321 ,  0.999898  ,  0.8497653 , -0.7609784 ,  0.9737437 ,\n",
       "         0.10488515,  0.9085994 ,  0.99626327,  0.94732237,  0.999101  ,\n",
       "         0.9794163 ,  0.99975556, -0.9999471 , -0.99982876,  0.95685714,\n",
       "        -0.9767133 , -0.99945974, -0.9999957 , -0.02074859, -0.9992264 ,\n",
       "        -0.9976457 , -0.01730537, -0.5995568 ,  0.9173174 ,  0.6598957 ,\n",
       "         0.8395431 ,  0.33586192,  0.7490907 , -0.9895178 ,  0.9132726 ,\n",
       "         0.674815  , -0.9716301 , -0.99797815, -0.99996865, -0.99877703,\n",
       "         0.981772  ,  0.9995909 , -0.9997363 ,  0.9999891 , -0.9999502 ,\n",
       "        -0.77328825,  0.99915373,  0.35761213, -0.16904004,  0.9826583 ,\n",
       "        -0.99867696,  0.9972985 ,  0.9976932 ,  0.9999987 ,  0.9995549 ,\n",
       "         0.9995158 , -0.8827246 , -0.9998626 , -0.99450856, -0.99960047,\n",
       "        -0.9999934 , -0.9987765 ,  0.78434503,  0.91779476, -0.99996525,\n",
       "         0.89452815,  0.9887242 ,  0.9999833 ,  0.996469  , -0.9995383 ,\n",
       "         0.30540267, -0.9999052 ,  0.86267924,  0.99997044, -0.9687265 ,\n",
       "        -0.9996459 , -0.4006024 ,  0.49567345,  0.9999062 , -0.06537919,\n",
       "         0.9752867 ,  0.82843053, -0.9325651 ,  0.97832423, -0.99972796,\n",
       "        -0.32899338,  0.9999375 , -0.67814845, -0.99998194, -0.28358978,\n",
       "        -0.8548497 , -0.99491775, -0.7943965 ,  0.9427198 ,  0.9931008 ,\n",
       "        -0.99918556, -0.957525  , -0.98837477,  0.82926714,  0.99645126,\n",
       "         0.99964833,  0.99834764,  0.7018795 ,  0.9031743 ,  0.9400457 ,\n",
       "        -0.87857896,  0.99768525,  0.9799166 , -0.9997924 ,  0.9994048 ,\n",
       "        -0.25231615,  0.55252165, -0.999999  ,  0.99857754, -0.52240586,\n",
       "         0.99954003,  0.9935401 , -0.64421165, -0.09514989, -0.89206004,\n",
       "         0.99850327,  0.99999386, -0.92464286, -0.9907228 , -0.9997799 ,\n",
       "        -0.9990271 , -0.99885935, -0.98665345, -0.94119817, -0.9979392 ,\n",
       "        -0.997819  , -0.7492871 ,  0.9574734 ,  0.9999952 ,  0.99990267,\n",
       "         0.99951786, -0.9849719 , -0.9657966 ,  0.9908846 , -0.7875783 ,\n",
       "         0.9448644 , -0.59161234, -0.9999985 , -0.9893587 , -0.9894552 ,\n",
       "         0.9978215 ,  0.61795473,  0.9688246 , -0.94247717,  0.9837388 ,\n",
       "         0.98076826, -0.99994534, -0.88152534, -0.9842837 ,  0.9693935 ,\n",
       "         0.99998873, -0.99401176,  0.98654646, -0.99743176,  0.5766474 ,\n",
       "         0.9824167 ,  0.97308934,  0.9894738 ,  0.8057498 ,  0.54650116,\n",
       "        -0.7939725 , -0.9792882 ,  0.6930915 ,  0.9947746 , -0.8351357 ,\n",
       "         0.79235315,  0.99960387, -0.9711923 ,  0.99809045,  0.22187158,\n",
       "        -0.36622354,  0.996218  ,  0.99997336, -0.55964375,  0.9810629 ,\n",
       "         0.832825  ,  0.9851553 ,  0.9997571 , -0.9672019 ,  0.9807905 ,\n",
       "        -0.01977498, -0.9792753 ,  0.21594532,  0.7334769 ,  0.999989  ,\n",
       "         0.40876383, -0.979289  , -0.9998971 ,  0.9909467 ,  0.9988899 ,\n",
       "         0.99999887, -0.93191636,  0.999374  , -0.00700144, -0.34489486,\n",
       "         0.7904391 ,  0.7527717 ,  0.8113258 ,  0.59258795,  0.93616575,\n",
       "         0.9998029 , -0.9998967 , -0.99997616, -0.9999989 ,  0.9999937 ,\n",
       "         0.9989037 , -0.6314399 , -0.9999975 ,  0.99929315, -0.94344765,\n",
       "         0.99270356,  0.9843523 ,  0.20989117, -0.39452058, -0.8133446 ,\n",
       "        -0.9992347 ,  0.13092336,  0.25932336,  0.93321645, -0.6757841 ,\n",
       "         0.99852365, -0.99835885,  0.2542385 ,  0.9999906 ,  0.08047733,\n",
       "         0.9996569 ,  0.39472812, -0.98857266,  0.99843854, -0.30800486,\n",
       "        -0.99957496, -0.97961074,  0.99979764,  0.9991444 , -0.25618458,\n",
       "         0.9921799 ,  0.9999259 , -0.91559047,  0.9998903 , -0.9998533 ,\n",
       "         0.9315009 , -0.99458104,  0.9999301 , -0.9854587 , -0.9537114 ,\n",
       "        -0.949815  , -0.3064076 , -0.19057451,  0.60222864,  0.9997679 ,\n",
       "         0.63680565,  0.9956539 ,  0.92940396, -0.8461053 , -0.9751798 ,\n",
       "        -0.9914499 ,  0.30959737, -0.9995797 ,  0.9433239 ,  0.88430476,\n",
       "        -0.9308331 , -0.9922396 , -0.99983793,  0.99922884,  0.07409599,\n",
       "        -0.99638975,  0.9998611 , -0.93392664, -0.99999434,  0.40086535,\n",
       "        -0.9995237 ,  0.5553443 ,  0.99379236,  0.9738797 ,  0.8844379 ,\n",
       "        -0.9997412 ,  0.9579941 ,  0.9997682 , -0.99998283,  0.96395767,\n",
       "        -0.81523186,  0.9950777 ,  0.33221802,  0.9879478 ,  0.86112463,\n",
       "        -0.8369198 ,  0.98605657,  0.84991866,  0.9795383 , -0.05629387,\n",
       "        -0.97935253, -0.99992955, -0.85128295,  0.64992785, -0.999963  ,\n",
       "        -0.9992631 , -0.99996495,  0.99999875,  0.9998929 ,  0.99993896,\n",
       "        -0.9724312 , -0.9971788 ,  0.9838449 ,  0.99574816, -0.9942648 ,\n",
       "        -0.85005635, -0.97216225,  0.9811205 ,  0.6179694 , -0.99914366,\n",
       "         0.04543274, -0.99997395, -0.86835796,  0.65605044, -0.847793  ,\n",
       "         0.9901041 ,  0.9999713 ,  0.99963605, -0.99913263, -0.9994095 ,\n",
       "        -0.9999639 , -0.9967827 ,  0.9997565 ,  0.9980774 ,  0.99990225,\n",
       "        -0.9710752 , -0.91389287,  0.99916077, -0.35430026,  0.9380445 ,\n",
       "        -0.9842904 , -0.9997752 , -0.99973357,  0.99142385, -0.99242795,\n",
       "        -0.99802136,  0.9413351 ,  0.9999699 , -0.553609  , -0.9999537 ,\n",
       "        -0.9352502 ,  0.9998577 ,  0.9999632 ,  0.9999978 , -0.74204326,\n",
       "         0.99932635, -0.99942213,  0.9962244 , -0.9994664 ,  0.9999024 ,\n",
       "        -0.9999449 ,  0.9999355 ,  0.999941  ,  0.9941507 ,  0.9936221 ,\n",
       "        -0.9991224 ,  0.9780994 , -0.9752493 , -0.84818435,  0.9891824 ,\n",
       "        -0.7413521 , -0.99954814,  0.30352026,  0.99935627, -0.93874264,\n",
       "         0.9999957 ,  0.99928296,  0.92585087,  0.9474498 , -0.9984057 ,\n",
       "         0.9575125 , -0.33406395, -0.9999958 ,  0.5315423 ,  0.9857416 ,\n",
       "         0.9873456 ,  0.9999741 ,  0.98439044,  0.99989694, -0.99924034,\n",
       "        -0.9775619 ,  0.97908646, -0.5226983 ,  0.06567989, -0.9998868 ,\n",
       "         0.99996674,  0.99999976, -0.9996135 , -0.99587536,  0.972273  ,\n",
       "         0.93456906,  0.9936664 ,  0.999322  ,  0.93810856,  0.32073262,\n",
       "         0.3885605 ,  0.98972774, -0.9999929 ,  0.17107679, -0.70455694,\n",
       "        -0.9627476 ,  0.99971646, -0.97705364,  0.980743  , -0.99930567,\n",
       "         0.999997  , -0.97510135, -0.09166066,  0.99982643,  0.98839015,\n",
       "        -0.9990832 ,  0.9997153 ,  0.6537361 , -0.9800646 , -0.97769326,\n",
       "        -0.99883306, -0.9991194 ,  0.7428509 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = title_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37new",
   "language": "python",
   "name": "py37_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
