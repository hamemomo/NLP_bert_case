{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim import optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss,BCEWithLogitsLoss\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "#from transformers.optimization import BertAdam, WarmupLinearSchedule\n",
    "from sklearn.metrics import precision_recall_curve,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news_content.csv')\n",
    "a= []\n",
    "for title in df['title']:\n",
    "    title = title.replace('| 政治 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 影音 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 節目 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 娛樂 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 焦點 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 觀點 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 國際 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 運動 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 房產 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 財經 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 兩岸 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 新奇 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 生活 | NOWnews 今日新聞','')\n",
    "    title = title.replace('| 地方 | NOWnews 今日新聞','')\n",
    "    a.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['Unnamed: 0','content'], axis=1)\n",
    "data['title'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data= shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.iloc[100:238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>視導潛艦防疫　海軍副司令唐華要求官兵勤洗手、戴口罩</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>巷仔內／黃國昌接大同獨董能查中資？還是為市場派洗白？</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>台灣抗疫「決勝關鍵」為何？紐時：流行病學家當副總統</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>涉嚴重違紀 北京：免去孫力軍公安部副部長職務</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>名家論壇》盧俊偉／後疫情時代加速中小型服務業數位轉型</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>鬧區「停車場vs蓋房收租」哪個好？知情人揭3優勢：爽賺</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>名家論壇》錢震宇／蔡政府讓人又急又難的紓困</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>房市／吸臭、除溼和清潔　咖啡渣廢物利用好省錢</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>台灣28天無本土案例！男揭陸網「一轉變」　台人看完笑了</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  news_label\n",
       "1      視導潛艦防疫　海軍副司令唐華要求官兵勤洗手、戴口罩            0\n",
       "197   房東不爽租客爆氣趕走！一開門全場嚇爛：我到底看了什麼           11\n",
       "157   巷仔內／黃國昌接大同獨董能查中資？還是為市場派洗白？            9\n",
       "80     台灣抗疫「決勝關鍵」為何？紐時：流行病學家當副總統            4\n",
       "178       涉嚴重違紀 北京：免去孫力軍公安部副部長職務           10\n",
       "..                            ...         ...\n",
       "92    名家論壇》盧俊偉／後疫情時代加速中小型服務業數位轉型            5\n",
       "220  鬧區「停車場vs蓋房收租」哪個好？知情人揭3優勢：爽賺           12\n",
       "91         名家論壇》錢震宇／蔡政府讓人又急又難的紓困            5\n",
       "140       房市／吸臭、除溼和清潔　咖啡渣廢物利用好省錢            8\n",
       "70   台灣28天無本土案例！男揭陸網「一轉變」　台人看完笑了            4\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=False)\n",
    "# 封装类\n",
    "class DataPrecessForSingleSentence(object):\n",
    "    def __init__(self, bert_tokenizer, max_workers=10):\n",
    "        \"\"\"\n",
    "        bert_tokenizer :分词器\n",
    "        dataset        :包含列名为'text'与'label'的pandas dataframe\n",
    "        \"\"\"\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        # 创建多线程池\n",
    "        self.pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        # 获取文本与标签\n",
    "    def get_input(self, dataset, max_seq_len=30):\n",
    "        \"\"\"\n",
    "        通过多线程（因为notebook中多进程使用存在一些问题）的方式对输入文本进行分词、ID化、截断、填充等流程得到最终的可用于模型输入的序列。\n",
    "        \n",
    "        入参:\n",
    "            dataset     : pandas的dataframe格式，包含两列，第一列为文本，第二列为标签。标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "            max_seq_len : 目标序列长度，该值需要预先对文本长度进行分别得到，可以设置为小于等于512（BERT的最长文本序列长度为512）的整数。\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "            labels      : 标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "        \n",
    "            \n",
    "        \"\"\"\n",
    "        sentences = dataset.iloc[:, 0].tolist()\n",
    "        labels = dataset.iloc[:, 1].tolist()\n",
    "        # 切词\n",
    "        tokens_seq = list(\n",
    "            self.pool.map(self.bert_tokenizer.tokenize, sentences))\n",
    "        # 获取定长序列及其mask\n",
    "        result = list(\n",
    "            self.pool.map(self.trunate_and_pad, tokens_seq,\n",
    "                          [max_seq_len] * len(tokens_seq)))\n",
    "        seqs = [i[0] for i in result]\n",
    "        seq_masks = [i[1] for i in result]\n",
    "        seq_segments = [i[2] for i in result]\n",
    "        return seqs, seq_masks, seq_segments, labels\n",
    "    def trunate_and_pad(self, seq, max_seq_len):\n",
    "        \"\"\"\n",
    "        1. 因为本类处理的是单句序列，按照BERT中的序列处理方式，需要在输入序列头尾分别拼接特殊字符'CLS'与'SEP'，\n",
    "           因此不包含两个特殊字符的序列长度应该小于等于max_seq_len-2，如果序列长度大于该值需要那么进行截断。\n",
    "        2. 对输入的序列 最终形成['CLS',seq,'SEP']的序列，该序列的长度如果小于max_seq_len，那么使用0进行填充。\n",
    "        \n",
    "        入参: \n",
    "            seq         : 输入序列，在本处其为单个句子。\n",
    "            max_seq_len : 拼接'CLS'与'SEP'这两个特殊字符后的序列长度\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "        \"\"\"\n",
    "        # 对超长序列进行截断\n",
    "        if len(seq) > (max_seq_len - 2):\n",
    "            seq = seq[0:(max_seq_len - 2)]\n",
    "        # 分别在首尾拼接特殊符号\n",
    "        seq = ['[CLS]'] + seq + ['[SEP]']\n",
    "        # ID化\n",
    "        seq = self.bert_tokenizer.convert_tokens_to_ids(seq)\n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (max_seq_len - len(seq))\n",
    "        # 创建seq_mask\n",
    "        seq_mask = [1] * len(seq) + padding\n",
    "        # 创建seq_segment\n",
    "        seq_segment = [0] * len(seq) + padding\n",
    "        # 对seq拼接填充序列\n",
    "        seq += padding\n",
    "        assert len(seq) == max_seq_len\n",
    "        assert len(seq_mask) == max_seq_len\n",
    "        assert len(seq_segment) == max_seq_len\n",
    "        return seq, seq_mask, seq_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)\n",
    "# 产生输入ju 数据\n",
    "seqs, seq_masks, seq_segments, labels = processor.get_input(dataset=data, max_seq_len=30)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=14)\n",
    "t_seqs = torch.tensor(seqs, dtype=torch.long)\n",
    "t_seq_masks = torch.tensor(seq_masks, dtype = torch.long)\n",
    "t_seq_segments = torch.tensor(seq_segments, dtype = torch.long)\n",
    "t_labels = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "train_data = TensorDataset(t_seqs, t_seq_masks, t_seq_segments, t_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloder = DataLoader(dataset= train_data, sampler= train_sampler,batch_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)\n",
    "# 产生输入ju 数据\n",
    "te_seqs, te_seq_masks, te_seq_segments, te_labels = processor.get_input(dataset=data_test, max_seq_len=30)\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=14)\n",
    "te_seqs = torch.tensor(te_seqs, dtype=torch.long)\n",
    "te_seq_masks = torch.tensor(te_seq_masks, dtype = torch.long)\n",
    "te_seq_segments = torch.tensor(te_seq_segments, dtype = torch.long)\n",
    "te_labels = torch.tensor(te_labels, dtype = torch.long)\n",
    "\n",
    "test_data = TensorDataset(te_seqs, te_seq_masks, te_seq_segments, te_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloder = DataLoader(dataset= test_data, sampler= test_sampler,batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "classification acc: 0.15151515151515152\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, train_dataloder, compute_acc=True)\n",
    "print(\"classification acc:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 53.047, acc: 0.101\n",
      "[epoch 1] loss: 53.047, acc: 0.162\n",
      "[epoch 2] loss: 49.262, acc: 0.167\n",
      "[epoch 2] loss: 49.262, acc: 0.273\n",
      "[epoch 3] loss: 44.512, acc: 0.225\n",
      "[epoch 3] loss: 44.512, acc: 0.374\n",
      "[epoch 4] loss: 40.517, acc: 0.304\n",
      "[epoch 4] loss: 40.517, acc: 0.545\n",
      "[epoch 5] loss: 35.821, acc: 0.384\n",
      "[epoch 5] loss: 35.821, acc: 0.677\n",
      "[epoch 6] loss: 32.207, acc: 0.391\n",
      "[epoch 6] loss: 32.207, acc: 0.707\n",
      "[epoch 7] loss: 29.470, acc: 0.435\n",
      "[epoch 7] loss: 29.470, acc: 0.758\n",
      "[epoch 8] loss: 26.752, acc: 0.457\n",
      "[epoch 8] loss: 26.752, acc: 0.798\n",
      "[epoch 9] loss: 23.357, acc: 0.428\n",
      "[epoch 9] loss: 23.357, acc: 0.838\n",
      "[epoch 10] loss: 20.851, acc: 0.420\n",
      "[epoch 10] loss: 20.851, acc: 0.848\n",
      "[epoch 11] loss: 19.368, acc: 0.478\n",
      "[epoch 11] loss: 19.368, acc: 0.859\n",
      "[epoch 12] loss: 17.279, acc: 0.435\n",
      "[epoch 12] loss: 17.279, acc: 0.859\n",
      "[epoch 13] loss: 16.160, acc: 0.478\n",
      "[epoch 13] loss: 16.160, acc: 0.798\n",
      "[epoch 14] loss: 15.100, acc: 0.464\n",
      "[epoch 14] loss: 15.100, acc: 0.859\n",
      "[epoch 15] loss: 14.009, acc: 0.449\n",
      "[epoch 15] loss: 14.009, acc: 0.848\n",
      "[epoch 16] loss: 12.955, acc: 0.464\n",
      "[epoch 16] loss: 12.955, acc: 0.838\n",
      "[epoch 17] loss: 12.196, acc: 0.464\n",
      "[epoch 17] loss: 12.196, acc: 0.879\n",
      "[epoch 18] loss: 10.854, acc: 0.478\n",
      "[epoch 18] loss: 10.854, acc: 0.838\n",
      "[epoch 19] loss: 10.406, acc: 0.471\n",
      "[epoch 19] loss: 10.406, acc: 0.879\n",
      "[epoch 20] loss: 9.964, acc: 0.493\n",
      "[epoch 20] loss: 9.964, acc: 0.818\n",
      "[epoch 21] loss: 9.555, acc: 0.457\n",
      "[epoch 21] loss: 9.555, acc: 0.859\n",
      "[epoch 22] loss: 9.626, acc: 0.493\n",
      "[epoch 22] loss: 9.626, acc: 0.859\n",
      "[epoch 23] loss: 9.244, acc: 0.464\n",
      "[epoch 23] loss: 9.244, acc: 0.859\n",
      "[epoch 24] loss: 8.637, acc: 0.442\n",
      "[epoch 24] loss: 8.637, acc: 0.879\n",
      "[epoch 25] loss: 9.013, acc: 0.449\n",
      "[epoch 25] loss: 9.013, acc: 0.859\n",
      "[epoch 26] loss: 8.121, acc: 0.457\n",
      "[epoch 26] loss: 8.121, acc: 0.879\n",
      "[epoch 27] loss: 8.924, acc: 0.478\n",
      "[epoch 27] loss: 8.924, acc: 0.859\n",
      "[epoch 28] loss: 7.810, acc: 0.471\n",
      "[epoch 28] loss: 7.810, acc: 0.869\n",
      "[epoch 29] loss: 8.166, acc: 0.486\n",
      "[epoch 29] loss: 8.166, acc: 0.869\n",
      "[epoch 30] loss: 7.336, acc: 0.449\n",
      "[epoch 30] loss: 7.336, acc: 0.808\n",
      "[epoch 31] loss: 7.671, acc: 0.457\n",
      "[epoch 31] loss: 7.671, acc: 0.899\n",
      "[epoch 32] loss: 7.424, acc: 0.471\n",
      "[epoch 32] loss: 7.424, acc: 0.889\n",
      "[epoch 33] loss: 6.994, acc: 0.493\n",
      "[epoch 33] loss: 6.994, acc: 0.879\n",
      "[epoch 34] loss: 7.198, acc: 0.457\n",
      "[epoch 34] loss: 7.198, acc: 0.869\n",
      "[epoch 35] loss: 7.372, acc: 0.464\n",
      "[epoch 35] loss: 7.372, acc: 0.889\n",
      "[epoch 36] loss: 6.970, acc: 0.464\n",
      "[epoch 36] loss: 6.970, acc: 0.869\n",
      "[epoch 37] loss: 6.726, acc: 0.493\n",
      "[epoch 37] loss: 6.726, acc: 0.859\n",
      "[epoch 38] loss: 6.565, acc: 0.478\n",
      "[epoch 38] loss: 6.565, acc: 0.838\n",
      "[epoch 39] loss: 6.879, acc: 0.464\n",
      "[epoch 39] loss: 6.879, acc: 0.899\n",
      "[epoch 40] loss: 6.904, acc: 0.449\n",
      "[epoch 40] loss: 6.904, acc: 0.909\n",
      "[epoch 41] loss: 6.224, acc: 0.486\n",
      "[epoch 41] loss: 6.224, acc: 0.828\n",
      "[epoch 42] loss: 6.329, acc: 0.514\n",
      "[epoch 42] loss: 6.329, acc: 0.869\n",
      "[epoch 43] loss: 6.546, acc: 0.500\n",
      "[epoch 43] loss: 6.546, acc: 0.869\n",
      "[epoch 44] loss: 6.336, acc: 0.486\n",
      "[epoch 44] loss: 6.336, acc: 0.869\n",
      "[epoch 45] loss: 6.166, acc: 0.464\n",
      "[epoch 45] loss: 6.166, acc: 0.889\n",
      "[epoch 46] loss: 5.886, acc: 0.471\n",
      "[epoch 46] loss: 5.886, acc: 0.818\n",
      "[epoch 47] loss: 6.365, acc: 0.464\n",
      "[epoch 47] loss: 6.365, acc: 0.838\n",
      "[epoch 48] loss: 5.915, acc: 0.464\n",
      "[epoch 48] loss: 5.915, acc: 0.818\n",
      "[epoch 49] loss: 5.849, acc: 0.457\n",
      "[epoch 49] loss: 5.849, acc: 0.869\n",
      "[epoch 50] loss: 5.985, acc: 0.478\n",
      "[epoch 50] loss: 5.985, acc: 0.859\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "EPOCHS = 50  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in train_dataloder:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "        #print(labels)\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    _, acc_test = get_predictions(model, test_dataloder, compute_acc=True)\n",
    "    _, acc_train = get_predictions(model, train_dataloder, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc_test))\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c4586ef32ccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extractor' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(extractor.device):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers.optimization import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataloder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.01\n",
    "    },\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-05)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存储每一个batch的loss\n",
    "loss_collect = []\n",
    "for i in trange(10, desc='Epoch'):\n",
    "    for step, batch_data in enumerate(tqdm.notebook.tqdm_notebook(train_dataloder, desc='Iteration')):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data\n",
    "        \n",
    "        print(batch_seq_segments)\n",
    "        # 对标签进行onehot编码\n",
    "        one_hot = torch.zeros(batch_labels.size(0), 28).long()\n",
    "        one_hot_batch_labels = one_hot.scatter_(\n",
    "            dim=1,\n",
    "            index=torch.unsqueeze(batch_labels, dim=1),\n",
    "            src=torch.ones(batch_labels.size(0), 28).long())\n",
    "\n",
    "        logits = model(batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = logits.softmax(dim=1)\n",
    "        loss_function = CrossEntropyLoss()\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        loss_collect.append(loss.item())\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37new",
   "language": "python",
   "name": "py37_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
